{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5004)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import lasagne\n",
    "from copy import deepcopy\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import random\n",
    "from skimage import exposure\n",
    "from skimage.morphology import binary_closing\n",
    "\n",
    "import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_patches(mri, label, half_patch_size=5, negative_subsample_ratio=500):\n",
    "    \n",
    "    assert mri.shape == label.shape\n",
    "    \n",
    "    z_size, x_size, y_size = mri.shape\n",
    "    positive_patches = []\n",
    "    negative_patches = []\n",
    "    \n",
    "    if np.sum(label) <= 0.5:\n",
    "        return ([], [])\n",
    "\n",
    "    for z in xrange(half_patch_size, z_size-half_patch_size):\n",
    "        if label[z,:,:].sum() > 1000: continue # workaround to remove white slices into the label dataset\n",
    "        for x in xrange(half_patch_size, x_size-half_patch_size):\n",
    "            for y in xrange(half_patch_size, y_size-half_patch_size):\n",
    "                if label[z,x,y] == 1:\n",
    "                    positive_patches.append(mri[z-half_patch_size:z+half_patch_size+1,x-half_patch_size:x+half_patch_size+1,y-half_patch_size:y+half_patch_size+1])\n",
    "                elif label[z,x,y] == 0:\n",
    "                    negative_patches.append(mri[z-half_patch_size:z+half_patch_size+1,x-half_patch_size:x+half_patch_size+1,y-half_patch_size:y+half_patch_size+1])\n",
    "    \n",
    "    random.shuffle(negative_patches)\n",
    "    number_of_negative_cases = int(len(negative_patches) / float(negative_subsample_ratio))\n",
    "    selected_negative_patches = deepcopy(negative_patches[:number_of_negative_cases])\n",
    "    del(negative_patches)\n",
    "    \n",
    "    return (positive_patches, selected_negative_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patchimg2differentview(patch):\n",
    "    \n",
    "    z_size, x_size, y_size = patch.shape\n",
    "    \n",
    "    X = np.zeros((z_size * 3, x_size, y_size), dtype=np.float32)\n",
    "    \n",
    "    counter = 0\n",
    "    for z in xrange(z_size):\n",
    "        X[counter,:,:] = patch[z,:,:]\n",
    "        counter += 1\n",
    "    for x in xrange(x_size):\n",
    "        X[counter,:,:] = patch[:,x,:]\n",
    "        counter += 1\n",
    "    for y in xrange(y_size):\n",
    "        X[counter,:,:] = patch[:,:,y]\n",
    "        counter += 1\n",
    "    \n",
    "    return X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patches2CNNformat(patches, label, half_patch_size=5):\n",
    "    \n",
    "    X = np.zeros((len(patches), 3 * ((2 * half_patch_size)+1), (half_patch_size*2)+1, (half_patch_size*2)+1), dtype=np.float32)\n",
    "    y = np.zeros((len(patches)), dtype=np.int32) * -1\n",
    "    \n",
    "    for i, patch in enumerate(patches):\n",
    "        X[i,:,:,:] = patchimg2differentview(patch)\n",
    "        y[i] = label\n",
    "    \n",
    "    assert -1 not in y\n",
    "    \n",
    "    return X.astype(np.float32), y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_resized_img(img, data_type = sitk.sitkFloat32):\n",
    "    \n",
    "    size = img.GetSize()\n",
    "    ratio = [1.0/i for i in img.GetSpacing()]\n",
    "    new_size = [int(size[i]/ratio[i]) for i in range(3)]\n",
    "    \n",
    "    rimage = sitk.Image(new_size, data_type)\n",
    "    rimage.SetSpacing((1,1,1))\n",
    "    rimage.SetOrigin(img.GetOrigin())\n",
    "    tx = sitk.Transform()\n",
    "    \n",
    "    interp = sitk.sitkLinear\n",
    "    if data_type == sitk.sitkInt16:\n",
    "        interp = sitk.sitkNearestNeighbor\n",
    "    \n",
    "    new_image = sitk.Resample(img, rimage, tx, interp, data_type)\n",
    "    \n",
    "    return sitk.GetArrayFromImage(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def needles2tips(only_needles, image_array, number_of_slices=3):\n",
    "    needles_masks_array = np.zeros_like(image_array).astype(float)  \n",
    "    for file_item in only_needles:\n",
    "        this_mask = file_item.astype(np.float)\n",
    "        if np.sum(this_mask) < (np.shape(this_mask)[0] * np.shape(this_mask)[1] * np.shape(this_mask)[2]):\n",
    "            this_mask = binary_closing(this_mask,selem=np.ones((3,3,3)))\n",
    "            found=False\n",
    "            row = np.shape(this_mask)[0]-1\n",
    "            while found==False and row > 0: #< np.shape(this_mask)[0]-1 :\n",
    "                #print(row)\n",
    "                this_row = this_mask[row,:,:]\n",
    "                if np.sum(this_row) > 0:\n",
    "                    #print(row)\n",
    "                    found = True\n",
    "                    temp = np.add(needles_masks_array[row:row+1+number_of_slices,:,:],this_mask[row:row+1+number_of_slices,:,:])\n",
    "                    temp[temp!=0] = 1\n",
    "                    needles_masks_array[row:row+1+number_of_slices,:,:] = temp \n",
    "                row -= 1\n",
    "    return needles_masks_array.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def needles2tips_PAOLO(needles, mri, number_of_slices=3):\n",
    "    tips = np.zeros_like(mri).astype(np.int32)\n",
    "    #print(tips.shape)\n",
    "    for needle in needles:\n",
    "        needle = needle.astype(np.int32)\n",
    "        #print(\"MIN %f, MAX %f\" % (needle.min(), needle.max()))\n",
    "        if np.sum(needle) < (np.shape(needle)[0] * np.shape(needle)[1] * np.shape(needle)[2]):\n",
    "            #print(\"Valid needle\")\n",
    "            needle = binary_closing(needle, selem=np.ones((3,3,3)))\n",
    "            needle[needle!=0]=1\n",
    "            #print(\" after closing: MIN %f, MAX %f \" % (needle.min(), needle.max()))\n",
    "            for z in range(np.shape(mri)[0]-1, 0, -1):\n",
    "                if 200 > np.sum(needle[z,:,:]) > 0.5 and z-number_of_slices-1 >= 0:\n",
    "                    #print(\" valid slice %d\" % z)\n",
    "                    tmp = deepcopy(needle)\n",
    "                    tmp[:z-number_of_slices-1,:,:] = 0\n",
    "                    tips[tmp!=0] = 1\n",
    "                    del(tmp)\n",
    "                    break\n",
    "    \n",
    "    tips[tips!=0]=1\n",
    "        \n",
    "    return tips.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_needles(needles, mri):\n",
    "    all_needles = np.zeros_like(mri).astype(np.int32)\n",
    "    \n",
    "    for needle in needles:\n",
    "        needle = needle.astype(np.int32)\n",
    "        needle[needle!=0]=1\n",
    "        \n",
    "        if np.sum(needle) < (needle.shape[0] * needle.shape[1] * needle.shape[2])/3.0:\n",
    "            all_needles[needle!=0] = 1\n",
    "    \n",
    "    all_needles[all_needles!=0]=1\n",
    "        \n",
    "    return all_needles.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_volume(img, half_patch_size=5):\n",
    "    npad = ((half_patch_size,half_patch_size),(half_patch_size,half_patch_size),(half_patch_size,half_patch_size))\n",
    "    return np.lib.pad(img, npad, \"constant\", constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_for_CNN(general_folder, half_patch_size=5):\n",
    "    folders_cases = os.listdir(general_folder)\n",
    "    \n",
    "    X_pos = np.ones((1, 3 * ((2 * half_patch_size)+1), (half_patch_size*2)+1, (half_patch_size*2)+1), dtype=np.float32) * -1.0\n",
    "    y_pos = np.ones((1), dtype=np.int32) * -1.0\n",
    "    \n",
    "    X_neg = np.ones((1, 3 * ((2 * half_patch_size)+1), (half_patch_size*2)+1, (half_patch_size*2)+1), dtype=np.float32) * -1.0\n",
    "    y_neg = np.ones((1), dtype=np.int32) * -1.0\n",
    "    \n",
    "    for folder_case in folders_cases:\n",
    "        print(\"Patient #%s\" % (folder_case))\n",
    "        full_case_path = general_folder + os.sep + folder_case\n",
    "        \n",
    "        volumetric_files = os.listdir(full_case_path)\n",
    "        \n",
    "        assert \"case.nrrd\" in volumetric_files\n",
    "        del(volumetric_files[volumetric_files.index(\"case.nrrd\")])\n",
    "        print(\" %d needles file\" %  (len(volumetric_files)))\n",
    "\n",
    "        \n",
    "        mri_sitk = sitk.ReadImage(full_case_path + os.sep + \"case.nrrd\")\n",
    "        \n",
    "        needles = []\n",
    "        valid_needles = 0\n",
    "        for volumetric_file in volumetric_files:\n",
    "            if volumetric_file == \"labelmap.nrrd\":\n",
    "                pass\n",
    "            label_sitk = sitk.ReadImage(full_case_path + os.sep + volumetric_file)\n",
    "            label = sitk.GetArrayFromImage(label_sitk)\n",
    "            background = int(np.around(np.percentile(label, 75), decimals=0))\n",
    "            #print('Background %d' % background)\n",
    "            filtered_label = np.zeros_like(label, dtype=np.int32)\n",
    "            filtered_label[label!=background] = 1\n",
    "            #print(np.sum(filtered_label))\n",
    "            \n",
    "            #label[label!=0]=1\n",
    "            if np.sum(filtered_label)>0:\n",
    "                needles.append(filtered_label)\n",
    "                valid_needles += 1\n",
    "                \n",
    "        print(\" %d valid needles\" %  (valid_needles))\n",
    "        \n",
    "        tips = merge_needles(needles, sitk.GetArrayFromImage(mri_sitk))\n",
    "        #tips_sitk = sitk.GetImageFromArray(tips)\n",
    "        #tips_sitk.CopyInformation(mri_sitk)\n",
    "        #tips = get_resized_img(tips_sitk, sitk.sitkInt16)\n",
    "        tips = pad_volume(tips, half_patch_size=half_patch_size)\n",
    "        tips[tips!=0]=1\n",
    "        \n",
    "        for z in range(tips.shape[0]):\n",
    "            if np.sum(tips[z,:,:]) > 500:\n",
    "                tips[z,:,:] = np.zeros_like(tips[z,:,:], dtype=np.int32)\n",
    "        \n",
    "        tips[tips!=0]=1\n",
    "        tips = tips.astype(np.int32)\n",
    "        #assert np.sum(tips) > 0.5\n",
    "        \n",
    "        mri = sitk.GetArrayFromImage(mri_sitk).astype(np.float32)\n",
    "        mri = pad_volume(mri, half_patch_size=half_patch_size)\n",
    "        \n",
    "        # DEBUG\n",
    "        #data_tag = str(datetime.datetime.now()).replace(\" \", \"_\")\n",
    "        #mri_sitk_DEBUG = sitk.GetImageFromArray(mri)\n",
    "        #tips_sitk_DEBUG = sitk.GetImageFromArray(tips)\n",
    "        #tips_sitk_DEBUG.CopyInformation(mri_sitk_DEBUG)\n",
    "        #sitk.WriteImage(mri_sitk_DEBUG, \"../DEBUG/mri_%s.nrrd\" % data_tag)\n",
    "        #sitk.WriteImage(tips_sitk_DEBUG, \"../DEBUG/tips_%s.nrrd\" % data_tag)\n",
    "        \n",
    "        positive_patches, negative_patches = extract_patches(mri, tips, half_patch_size=half_patch_size)\n",
    "        if len(positive_patches) > 0:\n",
    "            print(\" %d positive patches and %d negative patches\" % (len(positive_patches), len(negative_patches)))\n",
    "            X_temp_pos, y_temp_pos = patches2CNNformat(positive_patches, 1, half_patch_size=half_patch_size)\n",
    "            X_temp_neg, y_temp_neg = patches2CNNformat(negative_patches, 0, half_patch_size=half_patch_size)\n",
    "            \n",
    "            X_pos = np.concatenate((X_pos, X_temp_pos), axis=0)\n",
    "            y_pos = np.concatenate((y_pos, y_temp_pos), axis=0)\n",
    "            X_neg = np.concatenate((X_neg, X_temp_neg), axis=0)\n",
    "            y_neg = np.concatenate((y_neg, y_temp_neg), axis=0)\n",
    "    \n",
    "    assert -1 in X_pos[0,:,:,:] and y_pos[0] == -1\n",
    "    X_pos = X_pos[1:,:,:,:].astype(np.float32)\n",
    "    y_pos = y_pos[1:].astype(np.int32)\n",
    "    \n",
    "    assert -1 in X_neg[0,:,:,:] and y_neg[0] == -1\n",
    "    X_neg = X_neg[1:,:,:,:].astype(np.float32)\n",
    "    y_neg = y_neg[1:].astype(np.int32)\n",
    "    \n",
    "    return X_pos, y_pos, X_neg, y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_Xy_posneg(X_pos, y_pos, X_neg, y_neg, test_size1=0.20, test_size2=0.33):\n",
    "    \n",
    "    X_pos_train, X_pos_test, y_pos_train, y_pos_test = sklearn.cross_validation.train_test_split(X_pos, y_pos, test_size=test_size1)\n",
    "    X_pos_test, X_pos_val, y_pos_test, y_pos_val = sklearn.cross_validation.train_test_split(X_pos_test, y_pos_test, test_size=test_size2)\n",
    "\n",
    "    X_neg_train, X_neg_test, y_neg_train, y_neg_test = sklearn.cross_validation.train_test_split(X_neg, y_neg, test_size=test_size1)\n",
    "    X_neg_test, X_neg_val, y_neg_test, y_neg_val = sklearn.cross_validation.train_test_split(X_neg_test, y_neg_test, test_size=test_size2)\n",
    "\n",
    "    X_train = np.concatenate((X_neg_train, X_pos_train), axis=0).astype(np.float32)\n",
    "    y_train = np.concatenate((y_neg_train, y_pos_train), axis=0).astype(np.int32)\n",
    "\n",
    "    X_val = np.concatenate((X_neg_val, X_pos_val), axis=0).astype(np.float32)\n",
    "    y_val = np.concatenate((y_neg_val, y_pos_val), axis=0).astype(np.int32)\n",
    "\n",
    "    X_test = np.concatenate((X_neg_test, X_pos_test), axis=0).astype(np.float32)\n",
    "    y_test = np.concatenate((y_neg_test, y_pos_test), axis=0).astype(np.int32)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_patch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient #77\n",
      " 7 needles file\n",
      " 1 valid needles\n",
      " 900 positive patches and 19420 negative patches\n",
      "Patient #69\n",
      " 35 needles file\n",
      " 5 valid needles\n",
      " 179 positive patches and 20942 negative patches\n",
      "Patient #51\n",
      " 9 needles file\n",
      " 8 valid needles\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-0e6d5086249c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_neg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_for_CNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../LabelMaps\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalf_patch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhalf_patch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#saved_data = np.load('../patches_jun27_halfpatchsize5odd.npz')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#X, y = saved_data['arr_0'], saved_data['arr_1']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-60bd13556adc>\u001b[0m in \u001b[0;36mdata_for_CNN\u001b[1;34m(general_folder, half_patch_size)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mpositive_patches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_patches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_patches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtips\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalf_patch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhalf_patch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_patches\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" %d positive patches and %d negative patches\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-6b7eb3a0d955>\u001b[0m in \u001b[0;36mextract_patches\u001b[1;34m(mri, label, half_patch_size, negative_subsample_ratio)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mnumber_of_negative_cases\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_patches\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_subsample_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mselected_negative_patches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnumber_of_negative_cases\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[1;32mdel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpositive_patches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_negative_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_pos, y_pos, X_neg, y_neg = data_for_CNN(\"../LabelMaps\", half_patch_size=half_patch_size)\n",
    "#saved_data = np.load('../patches_jun27_halfpatchsize5odd.npz')\n",
    "#X, y = saved_data['arr_0'], saved_data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.savez('../patches_jul1_halfpatchsize5odd.npz', X_pos, y_pos, X_neg, y_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = join_Xy_posneg(X_pos, y_pos, X_neg, y_neg, test_size1=0.20, test_size2=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, s = X_train.mean(), X_train.std()\n",
    "\n",
    "X_train -= m\n",
    "X_train /= s\n",
    "\n",
    "X_val -= m\n",
    "X_val /= s\n",
    "\n",
    "X_test -= m\n",
    "X_test /= s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((615052, 33, 11, 11), (103021, 33, 11, 11), (50744, 33, 11, 11))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=True):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(single_entry_shape, input_var=None):\n",
    "    \n",
    "    network = lasagne.layers.InputLayer(shape=(None, single_entry_shape[0], single_entry_shape[1], \n",
    "                                               single_entry_shape[2]),\n",
    "                                        input_var=input_var)\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=480, filter_size=(3, 3),  #120\n",
    "            nonlinearity=lasagne.nonlinearities.leaky_rectify,\n",
    "            W=lasagne.init.HeNormal())\n",
    "    #network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=240, filter_size=(2, 2), #120\n",
    "            nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "           lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=120, #120*2*2\n",
    "           nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "           lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=60,\n",
    "           nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=2,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 550\n",
    "batchsize = 32\n",
    "single_entry_shape = X_train.shape[1:]\n",
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "network = build_cnn(single_entry_shape, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1 started on 2016-07-01 21:29\n",
      "Epoch 1 of 550 took 181.063s\n",
      "  training loss:\t\t0.087954\n",
      "  validation loss:\t\t0.048860\n",
      "  validation accuracy:\t\t98.34 %\n",
      "Epoch 2 started on 2016-07-01 21:32\n",
      "Epoch 2 of 550 took 180.973s\n",
      "  training loss:\t\t0.047753\n",
      "  validation loss:\t\t0.028319\n",
      "  validation accuracy:\t\t98.93 %\n",
      "Epoch 3 started on 2016-07-01 21:35\n",
      "Epoch 3 of 550 took 180.972s\n",
      "  training loss:\t\t0.033122\n",
      "  validation loss:\t\t0.022259\n",
      "  validation accuracy:\t\t99.23 %\n",
      "Epoch 4 started on 2016-07-01 21:38\n",
      "Epoch 4 of 550 took 181.007s\n",
      "  training loss:\t\t0.026936\n",
      "  validation loss:\t\t0.025055\n",
      "  validation accuracy:\t\t99.14 %\n",
      "Epoch 5 started on 2016-07-01 21:42\n",
      "Epoch 5 of 550 took 180.985s\n",
      "  training loss:\t\t0.023215\n",
      "  validation loss:\t\t0.019823\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 6 started on 2016-07-01 21:45\n",
      "Epoch 6 of 550 took 180.974s\n",
      "  training loss:\t\t0.020191\n",
      "  validation loss:\t\t0.014908\n",
      "  validation accuracy:\t\t99.50 %\n",
      "Epoch 7 started on 2016-07-01 21:48\n",
      "Epoch 7 of 550 took 180.990s\n",
      "  training loss:\t\t0.018108\n",
      "  validation loss:\t\t0.015447\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 8 started on 2016-07-01 21:51\n",
      "Epoch 8 of 550 took 181.002s\n",
      "  training loss:\t\t0.016421\n",
      "  validation loss:\t\t0.014033\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 9 started on 2016-07-01 21:54\n",
      "Epoch 9 of 550 took 181.017s\n",
      "  training loss:\t\t0.015107\n",
      "  validation loss:\t\t0.012108\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 10 started on 2016-07-01 21:57\n",
      "Epoch 10 of 550 took 181.033s\n",
      "  training loss:\t\t0.014026\n",
      "  validation loss:\t\t0.013913\n",
      "  validation accuracy:\t\t99.54 %\n",
      "Epoch 11 started on 2016-07-01 22:00\n",
      "Epoch 11 of 550 took 181.018s\n",
      "  training loss:\t\t0.012908\n",
      "  validation loss:\t\t0.011039\n",
      "  validation accuracy:\t\t99.64 %\n",
      "Epoch 12 started on 2016-07-01 22:03\n",
      "Epoch 12 of 550 took 181.061s\n",
      "  training loss:\t\t0.012273\n",
      "  validation loss:\t\t0.011376\n",
      "  validation accuracy:\t\t99.61 %\n",
      "Epoch 13 started on 2016-07-01 22:06\n",
      "Epoch 13 of 550 took 181.023s\n",
      "  training loss:\t\t0.011681\n",
      "  validation loss:\t\t0.009927\n",
      "  validation accuracy:\t\t99.67 %\n",
      "Epoch 14 started on 2016-07-01 22:09\n",
      "Epoch 14 of 550 took 181.020s\n",
      "  training loss:\t\t0.010795\n",
      "  validation loss:\t\t0.010330\n",
      "  validation accuracy:\t\t99.66 %\n",
      "Epoch 15 started on 2016-07-01 22:12\n",
      "Epoch 15 of 550 took 181.048s\n",
      "  training loss:\t\t0.010141\n",
      "  validation loss:\t\t0.010191\n",
      "  validation accuracy:\t\t99.67 %\n",
      "Epoch 16 started on 2016-07-01 22:15\n",
      "Epoch 16 of 550 took 181.023s\n",
      "  training loss:\t\t0.009458\n",
      "  validation loss:\t\t0.008484\n",
      "  validation accuracy:\t\t99.73 %\n",
      "Epoch 17 started on 2016-07-01 22:18\n",
      "Epoch 17 of 550 took 181.074s\n",
      "  training loss:\t\t0.008878\n",
      "  validation loss:\t\t0.009778\n",
      "  validation accuracy:\t\t99.69 %\n",
      "Epoch 18 started on 2016-07-01 22:21\n",
      "Epoch 18 of 550 took 181.076s\n",
      "  training loss:\t\t0.008525\n",
      "  validation loss:\t\t0.009363\n",
      "  validation accuracy:\t\t99.71 %\n",
      "Epoch 19 started on 2016-07-01 22:24\n",
      "Epoch 19 of 550 took 181.057s\n",
      "  training loss:\t\t0.008210\n",
      "  validation loss:\t\t0.011467\n",
      "  validation accuracy:\t\t99.59 %\n",
      "Epoch 20 started on 2016-07-01 22:27\n",
      "Epoch 20 of 550 took 181.052s\n",
      "  training loss:\t\t0.007832\n",
      "  validation loss:\t\t0.009082\n",
      "  validation accuracy:\t\t99.70 %\n",
      "Epoch 21 started on 2016-07-01 22:30\n",
      "Epoch 21 of 550 took 181.015s\n",
      "  training loss:\t\t0.007180\n",
      "  validation loss:\t\t0.007976\n",
      "  validation accuracy:\t\t99.73 %\n",
      "Epoch 22 started on 2016-07-01 22:33\n",
      "Epoch 22 of 550 took 181.072s\n",
      "  training loss:\t\t0.007162\n",
      "  validation loss:\t\t0.006848\n",
      "  validation accuracy:\t\t99.78 %\n",
      "Epoch 23 started on 2016-07-01 22:36\n",
      "Epoch 23 of 550 took 181.052s\n",
      "  training loss:\t\t0.006707\n",
      "  validation loss:\t\t0.006822\n",
      "  validation accuracy:\t\t99.79 %\n",
      "Epoch 24 started on 2016-07-01 22:39\n",
      "Epoch 24 of 550 took 181.040s\n",
      "  training loss:\t\t0.006222\n",
      "  validation loss:\t\t0.008780\n",
      "  validation accuracy:\t\t99.73 %\n",
      "Epoch 25 started on 2016-07-01 22:42\n",
      "Epoch 25 of 550 took 181.054s\n",
      "  training loss:\t\t0.006158\n",
      "  validation loss:\t\t0.012908\n",
      "  validation accuracy:\t\t99.58 %\n",
      "Epoch 26 started on 2016-07-01 22:45\n",
      "Epoch 26 of 550 took 181.092s\n",
      "  training loss:\t\t0.005728\n",
      "  validation loss:\t\t0.008066\n",
      "  validation accuracy:\t\t99.75 %\n",
      "Epoch 27 started on 2016-07-01 22:48\n",
      "Epoch 27 of 550 took 181.071s\n",
      "  training loss:\t\t0.005825\n",
      "  validation loss:\t\t0.007223\n",
      "  validation accuracy:\t\t99.76 %\n",
      "Epoch 28 started on 2016-07-01 22:51\n",
      "Epoch 28 of 550 took 181.067s\n",
      "  training loss:\t\t0.005557\n",
      "  validation loss:\t\t0.007933\n",
      "  validation accuracy:\t\t99.75 %\n",
      "Epoch 29 started on 2016-07-01 22:54\n",
      "Epoch 29 of 550 took 181.025s\n",
      "  training loss:\t\t0.005173\n",
      "  validation loss:\t\t0.006514\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 30 started on 2016-07-01 22:57\n",
      "Epoch 30 of 550 took 181.047s\n",
      "  training loss:\t\t0.005139\n",
      "  validation loss:\t\t0.008024\n",
      "  validation accuracy:\t\t99.75 %\n",
      "Epoch 31 started on 2016-07-01 23:00\n",
      "Epoch 31 of 550 took 181.061s\n",
      "  training loss:\t\t0.004803\n",
      "  validation loss:\t\t0.006808\n",
      "  validation accuracy:\t\t99.79 %\n",
      "Epoch 32 started on 2016-07-01 23:03\n",
      "Epoch 32 of 550 took 181.060s\n",
      "  training loss:\t\t0.004930\n",
      "  validation loss:\t\t0.008105\n",
      "  validation accuracy:\t\t99.77 %\n",
      "Epoch 33 started on 2016-07-01 23:06\n",
      "Epoch 33 of 550 took 181.036s\n",
      "  training loss:\t\t0.004320\n",
      "  validation loss:\t\t0.007194\n",
      "  validation accuracy:\t\t99.79 %\n",
      "Epoch 34 started on 2016-07-01 23:09\n",
      "Epoch 34 of 550 took 181.015s\n",
      "  training loss:\t\t0.004330\n",
      "  validation loss:\t\t0.006429\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 35 started on 2016-07-01 23:12\n",
      "Epoch 35 of 550 took 180.978s\n",
      "  training loss:\t\t0.004546\n",
      "  validation loss:\t\t0.006616\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 36 started on 2016-07-01 23:15\n",
      "Epoch 36 of 550 took 181.017s\n",
      "  training loss:\t\t0.003960\n",
      "  validation loss:\t\t0.007332\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 37 started on 2016-07-01 23:18\n",
      "Epoch 37 of 550 took 181.000s\n",
      "  training loss:\t\t0.003721\n",
      "  validation loss:\t\t0.006852\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 38 started on 2016-07-01 23:21\n",
      "Epoch 38 of 550 took 181.005s\n",
      "  training loss:\t\t0.003488\n",
      "  validation loss:\t\t0.007243\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 39 started on 2016-07-01 23:24\n",
      "Epoch 39 of 550 took 181.018s\n",
      "  training loss:\t\t0.004074\n",
      "  validation loss:\t\t0.008832\n",
      "  validation accuracy:\t\t99.74 %\n",
      "Epoch 40 started on 2016-07-01 23:27\n",
      "Epoch 40 of 550 took 181.021s\n",
      "  training loss:\t\t0.004016\n",
      "  validation loss:\t\t0.007706\n",
      "  validation accuracy:\t\t99.78 %\n",
      "Epoch 41 started on 2016-07-01 23:30\n",
      "Epoch 41 of 550 took 181.014s\n",
      "  training loss:\t\t0.003367\n",
      "  validation loss:\t\t0.009290\n",
      "  validation accuracy:\t\t99.72 %\n",
      "Epoch 42 started on 2016-07-01 23:33\n",
      "Epoch 42 of 550 took 181.015s\n",
      "  training loss:\t\t0.003550\n",
      "  validation loss:\t\t0.008129\n",
      "  validation accuracy:\t\t99.77 %\n",
      "Epoch 43 started on 2016-07-01 23:36\n",
      "Epoch 43 of 550 took 181.001s\n",
      "  training loss:\t\t0.003335\n",
      "  validation loss:\t\t0.007258\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 44 started on 2016-07-01 23:39\n",
      "Epoch 44 of 550 took 181.008s\n",
      "  training loss:\t\t0.003179\n",
      "  validation loss:\t\t0.005764\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 45 started on 2016-07-01 23:42\n",
      "Epoch 45 of 550 took 181.005s\n",
      "  training loss:\t\t0.002990\n",
      "  validation loss:\t\t0.007083\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 46 started on 2016-07-01 23:45\n",
      "Epoch 46 of 550 took 181.010s\n",
      "  training loss:\t\t0.003030\n",
      "  validation loss:\t\t0.009134\n",
      "  validation accuracy:\t\t99.75 %\n",
      "Epoch 47 started on 2016-07-01 23:48\n",
      "Epoch 47 of 550 took 180.949s\n",
      "  training loss:\t\t0.003267\n",
      "  validation loss:\t\t0.006043\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 48 started on 2016-07-01 23:51\n",
      "Epoch 48 of 550 took 180.957s\n",
      "  training loss:\t\t0.003099\n",
      "  validation loss:\t\t0.006412\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 49 started on 2016-07-01 23:54\n",
      "Epoch 49 of 550 took 180.958s\n",
      "  training loss:\t\t0.002980\n",
      "  validation loss:\t\t0.006318\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 50 started on 2016-07-01 23:57\n",
      "Epoch 50 of 550 took 180.985s\n",
      "  training loss:\t\t0.002930\n",
      "  validation loss:\t\t0.006319\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 51 started on 2016-07-02 00:00\n",
      "Epoch 51 of 550 took 180.944s\n",
      "  training loss:\t\t0.002662\n",
      "  validation loss:\t\t0.006487\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 52 started on 2016-07-02 00:03\n",
      "Epoch 52 of 550 took 180.946s\n",
      "  training loss:\t\t0.002648\n",
      "  validation loss:\t\t0.006279\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 53 started on 2016-07-02 00:06\n",
      "Epoch 53 of 550 took 180.958s\n",
      "  training loss:\t\t0.002737\n",
      "  validation loss:\t\t0.006492\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 54 started on 2016-07-02 00:09\n",
      "Epoch 54 of 550 took 180.974s\n",
      "  training loss:\t\t0.002947\n",
      "  validation loss:\t\t0.005365\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 55 started on 2016-07-02 00:12\n",
      "Epoch 55 of 550 took 180.937s\n",
      "  training loss:\t\t0.002403\n",
      "  validation loss:\t\t0.006208\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 56 started on 2016-07-02 00:15\n",
      "Epoch 56 of 550 took 180.960s\n",
      "  training loss:\t\t0.002544\n",
      "  validation loss:\t\t0.007818\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 57 started on 2016-07-02 00:18\n",
      "Epoch 57 of 550 took 180.948s\n",
      "  training loss:\t\t0.002366\n",
      "  validation loss:\t\t0.006825\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 58 started on 2016-07-02 00:21\n",
      "Epoch 58 of 550 took 180.954s\n",
      "  training loss:\t\t0.002333\n",
      "  validation loss:\t\t0.006362\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 59 started on 2016-07-02 00:24\n",
      "Epoch 59 of 550 took 180.968s\n",
      "  training loss:\t\t0.002391\n",
      "  validation loss:\t\t0.005988\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 60 started on 2016-07-02 00:27\n",
      "Epoch 60 of 550 took 180.917s\n",
      "  training loss:\t\t0.002493\n",
      "  validation loss:\t\t0.006118\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 61 started on 2016-07-02 00:30\n",
      "Epoch 61 of 550 took 180.927s\n",
      "  training loss:\t\t0.002020\n",
      "  validation loss:\t\t0.005890\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 62 started on 2016-07-02 00:33\n",
      "Epoch 62 of 550 took 180.952s\n",
      "  training loss:\t\t0.002312\n",
      "  validation loss:\t\t0.007041\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 63 started on 2016-07-02 00:36\n",
      "Epoch 63 of 550 took 180.963s\n",
      "  training loss:\t\t0.003176\n",
      "  validation loss:\t\t0.006661\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 64 started on 2016-07-02 00:39\n",
      "Epoch 64 of 550 took 180.936s\n",
      "  training loss:\t\t0.002396\n",
      "  validation loss:\t\t0.007019\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 65 started on 2016-07-02 00:43\n",
      "Epoch 65 of 550 took 180.936s\n",
      "  training loss:\t\t0.001832\n",
      "  validation loss:\t\t0.012941\n",
      "  validation accuracy:\t\t99.72 %\n",
      "Epoch 66 started on 2016-07-02 00:46\n",
      "Epoch 66 of 550 took 180.941s\n",
      "  training loss:\t\t0.001770\n",
      "  validation loss:\t\t0.006183\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 67 started on 2016-07-02 00:49\n",
      "Epoch 67 of 550 took 180.962s\n",
      "  training loss:\t\t0.002118\n",
      "  validation loss:\t\t0.006475\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 68 started on 2016-07-02 00:52\n",
      "Epoch 68 of 550 took 181.002s\n",
      "  training loss:\t\t0.001939\n",
      "  validation loss:\t\t0.006760\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 69 started on 2016-07-02 00:55\n",
      "Epoch 69 of 550 took 180.988s\n",
      "  training loss:\t\t0.001924\n",
      "  validation loss:\t\t0.007250\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 70 started on 2016-07-02 00:58\n",
      "Epoch 70 of 550 took 180.971s\n",
      "  training loss:\t\t0.001506\n",
      "  validation loss:\t\t0.006790\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 71 started on 2016-07-02 01:01\n",
      "Epoch 71 of 550 took 180.931s\n",
      "  training loss:\t\t0.001612\n",
      "  validation loss:\t\t0.007649\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 72 started on 2016-07-02 01:04\n",
      "Epoch 72 of 550 took 180.996s\n",
      "  training loss:\t\t0.002043\n",
      "  validation loss:\t\t0.008682\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 73 started on 2016-07-02 01:07\n",
      "Epoch 73 of 550 took 180.972s\n",
      "  training loss:\t\t0.002046\n",
      "  validation loss:\t\t0.007806\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 74 started on 2016-07-02 01:10\n",
      "Epoch 74 of 550 took 180.958s\n",
      "  training loss:\t\t0.001948\n",
      "  validation loss:\t\t0.006960\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 75 started on 2016-07-02 01:13\n",
      "Epoch 75 of 550 took 180.996s\n",
      "  training loss:\t\t0.001577\n",
      "  validation loss:\t\t0.008562\n",
      "  validation accuracy:\t\t99.78 %\n",
      "Epoch 76 started on 2016-07-02 01:16\n",
      "Epoch 76 of 550 took 180.974s\n",
      "  training loss:\t\t0.001619\n",
      "  validation loss:\t\t0.007916\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 77 started on 2016-07-02 01:19\n",
      "Epoch 77 of 550 took 180.953s\n",
      "  training loss:\t\t0.001581\n",
      "  validation loss:\t\t0.007062\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 78 started on 2016-07-02 01:22\n",
      "Epoch 78 of 550 took 180.925s\n",
      "  training loss:\t\t0.001564\n",
      "  validation loss:\t\t0.006194\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 79 started on 2016-07-02 01:25\n",
      "Epoch 79 of 550 took 180.945s\n",
      "  training loss:\t\t0.001324\n",
      "  validation loss:\t\t0.006637\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 80 started on 2016-07-02 01:28\n",
      "Epoch 80 of 550 took 180.948s\n",
      "  training loss:\t\t0.001803\n",
      "  validation loss:\t\t0.007911\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 81 started on 2016-07-02 01:31\n",
      "Epoch 81 of 550 took 180.939s\n",
      "  training loss:\t\t0.001568\n",
      "  validation loss:\t\t0.008773\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 82 started on 2016-07-02 01:34\n",
      "Epoch 82 of 550 took 180.953s\n",
      "  training loss:\t\t0.001947\n",
      "  validation loss:\t\t0.006367\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 83 started on 2016-07-02 01:37\n",
      "Epoch 83 of 550 took 180.951s\n",
      "  training loss:\t\t0.001534\n",
      "  validation loss:\t\t0.008350\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 84 started on 2016-07-02 01:40\n",
      "Epoch 84 of 550 took 180.934s\n",
      "  training loss:\t\t0.001698\n",
      "  validation loss:\t\t0.006522\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 85 started on 2016-07-02 01:43\n",
      "Epoch 85 of 550 took 180.910s\n",
      "  training loss:\t\t0.001498\n",
      "  validation loss:\t\t0.006280\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 86 started on 2016-07-02 01:46\n",
      "Epoch 86 of 550 took 180.979s\n",
      "  training loss:\t\t0.001403\n",
      "  validation loss:\t\t0.009210\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 87 started on 2016-07-02 01:49\n",
      "Epoch 87 of 550 took 180.965s\n",
      "  training loss:\t\t0.001470\n",
      "  validation loss:\t\t0.009461\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 88 started on 2016-07-02 01:52\n",
      "Epoch 88 of 550 took 180.976s\n",
      "  training loss:\t\t0.001485\n",
      "  validation loss:\t\t0.008182\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 89 started on 2016-07-02 01:55\n",
      "Epoch 89 of 550 took 181.019s\n",
      "  training loss:\t\t0.001538\n",
      "  validation loss:\t\t0.007581\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 90 started on 2016-07-02 01:58\n",
      "Epoch 90 of 550 took 180.972s\n",
      "  training loss:\t\t0.001587\n",
      "  validation loss:\t\t0.005818\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 91 started on 2016-07-02 02:01\n",
      "Epoch 91 of 550 took 180.987s\n",
      "  training loss:\t\t0.001604\n",
      "  validation loss:\t\t0.007162\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 92 started on 2016-07-02 02:04\n",
      "Epoch 92 of 550 took 180.984s\n",
      "  training loss:\t\t0.001394\n",
      "  validation loss:\t\t0.008436\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 93 started on 2016-07-02 02:07\n",
      "Epoch 93 of 550 took 180.958s\n",
      "  training loss:\t\t0.001405\n",
      "  validation loss:\t\t0.008618\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 94 started on 2016-07-02 02:10\n",
      "Epoch 94 of 550 took 180.949s\n",
      "  training loss:\t\t0.001312\n",
      "  validation loss:\t\t0.007793\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 95 started on 2016-07-02 02:13\n",
      "Epoch 95 of 550 took 180.947s\n",
      "  training loss:\t\t0.001105\n",
      "  validation loss:\t\t0.007771\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 96 started on 2016-07-02 02:16\n",
      "Epoch 96 of 550 took 180.956s\n",
      "  training loss:\t\t0.001269\n",
      "  validation loss:\t\t0.007180\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 97 started on 2016-07-02 02:19\n",
      "Epoch 97 of 550 took 180.939s\n",
      "  training loss:\t\t0.001182\n",
      "  validation loss:\t\t0.006713\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 98 started on 2016-07-02 02:22\n",
      "Epoch 98 of 550 took 180.920s\n",
      "  training loss:\t\t0.001207\n",
      "  validation loss:\t\t0.006748\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 99 started on 2016-07-02 02:25\n",
      "Epoch 99 of 550 took 180.957s\n",
      "  training loss:\t\t0.001110\n",
      "  validation loss:\t\t0.006757\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 100 started on 2016-07-02 02:28\n",
      "Epoch 100 of 550 took 180.914s\n",
      "  training loss:\t\t0.001273\n",
      "  validation loss:\t\t0.009810\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 101 started on 2016-07-02 02:31\n",
      "Epoch 101 of 550 took 180.953s\n",
      "  training loss:\t\t0.001146\n",
      "  validation loss:\t\t0.007722\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 102 started on 2016-07-02 02:34\n",
      "Epoch 102 of 550 took 180.966s\n",
      "  training loss:\t\t0.001417\n",
      "  validation loss:\t\t0.008676\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 103 started on 2016-07-02 02:37\n",
      "Epoch 103 of 550 took 180.959s\n",
      "  training loss:\t\t0.001187\n",
      "  validation loss:\t\t0.006152\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 104 started on 2016-07-02 02:40\n",
      "Epoch 104 of 550 took 180.966s\n",
      "  training loss:\t\t0.001091\n",
      "  validation loss:\t\t0.007206\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 105 started on 2016-07-02 02:43\n",
      "Epoch 105 of 550 took 180.970s\n",
      "  training loss:\t\t0.001121\n",
      "  validation loss:\t\t0.006357\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 106 started on 2016-07-02 02:46\n",
      "Epoch 106 of 550 took 180.974s\n",
      "  training loss:\t\t0.001187\n",
      "  validation loss:\t\t0.010543\n",
      "  validation accuracy:\t\t99.79 %\n",
      "Epoch 107 started on 2016-07-02 02:49\n",
      "Epoch 107 of 550 took 180.951s\n",
      "  training loss:\t\t0.001327\n",
      "  validation loss:\t\t0.006074\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 108 started on 2016-07-02 02:52\n",
      "Epoch 108 of 550 took 180.939s\n",
      "  training loss:\t\t0.001289\n",
      "  validation loss:\t\t0.006856\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 109 started on 2016-07-02 02:55\n",
      "Epoch 109 of 550 took 180.955s\n",
      "  training loss:\t\t0.000948\n",
      "  validation loss:\t\t0.006376\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 110 started on 2016-07-02 02:58\n",
      "Epoch 110 of 550 took 180.942s\n",
      "  training loss:\t\t0.000917\n",
      "  validation loss:\t\t0.008372\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 111 started on 2016-07-02 03:01\n",
      "Epoch 111 of 550 took 180.916s\n",
      "  training loss:\t\t0.000916\n",
      "  validation loss:\t\t0.007221\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 112 started on 2016-07-02 03:04\n",
      "Epoch 112 of 550 took 180.944s\n",
      "  training loss:\t\t0.000930\n",
      "  validation loss:\t\t0.007774\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 113 started on 2016-07-02 03:07\n",
      "Epoch 113 of 550 took 180.929s\n",
      "  training loss:\t\t0.001072\n",
      "  validation loss:\t\t0.008636\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 114 started on 2016-07-02 03:10\n",
      "Epoch 114 of 550 took 180.932s\n",
      "  training loss:\t\t0.001015\n",
      "  validation loss:\t\t0.009170\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 115 started on 2016-07-02 03:13\n",
      "Epoch 115 of 550 took 180.916s\n",
      "  training loss:\t\t0.001103\n",
      "  validation loss:\t\t0.007870\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 116 started on 2016-07-02 03:16\n",
      "Epoch 116 of 550 took 180.905s\n",
      "  training loss:\t\t0.000912\n",
      "  validation loss:\t\t0.007977\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 117 started on 2016-07-02 03:19\n",
      "Epoch 117 of 550 took 180.900s\n",
      "  training loss:\t\t0.001209\n",
      "  validation loss:\t\t0.008604\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 118 started on 2016-07-02 03:22\n",
      "Epoch 118 of 550 took 180.926s\n",
      "  training loss:\t\t0.001232\n",
      "  validation loss:\t\t0.007701\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 119 started on 2016-07-02 03:25\n",
      "Epoch 119 of 550 took 180.963s\n",
      "  training loss:\t\t0.000972\n",
      "  validation loss:\t\t0.007898\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 120 started on 2016-07-02 03:28\n",
      "Epoch 120 of 550 took 180.950s\n",
      "  training loss:\t\t0.001070\n",
      "  validation loss:\t\t0.007928\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 121 started on 2016-07-02 03:31\n",
      "Epoch 121 of 550 took 180.946s\n",
      "  training loss:\t\t0.000898\n",
      "  validation loss:\t\t0.007486\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 122 started on 2016-07-02 03:34\n",
      "Epoch 122 of 550 took 180.965s\n",
      "  training loss:\t\t0.000945\n",
      "  validation loss:\t\t0.006304\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 123 started on 2016-07-02 03:37\n",
      "Epoch 123 of 550 took 180.972s\n",
      "  training loss:\t\t0.000990\n",
      "  validation loss:\t\t0.008245\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 124 started on 2016-07-02 03:40\n",
      "Epoch 124 of 550 took 180.981s\n",
      "  training loss:\t\t0.001483\n",
      "  validation loss:\t\t0.007427\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 125 started on 2016-07-02 03:43\n",
      "Epoch 125 of 550 took 180.972s\n",
      "  training loss:\t\t0.001001\n",
      "  validation loss:\t\t0.006699\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 126 started on 2016-07-02 03:46\n",
      "Epoch 126 of 550 took 180.925s\n",
      "  training loss:\t\t0.000964\n",
      "  validation loss:\t\t0.010072\n",
      "  validation accuracy:\t\t99.80 %\n",
      "Epoch 127 started on 2016-07-02 03:49\n",
      "Epoch 127 of 550 took 180.944s\n",
      "  training loss:\t\t0.000959\n",
      "  validation loss:\t\t0.008572\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 128 started on 2016-07-02 03:53\n",
      "Epoch 128 of 550 took 180.972s\n",
      "  training loss:\t\t0.001045\n",
      "  validation loss:\t\t0.006264\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 129 started on 2016-07-02 03:56\n",
      "Epoch 129 of 550 took 180.951s\n",
      "  training loss:\t\t0.000754\n",
      "  validation loss:\t\t0.006430\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 130 started on 2016-07-02 03:59\n",
      "Epoch 130 of 550 took 180.907s\n",
      "  training loss:\t\t0.000969\n",
      "  validation loss:\t\t0.007767\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 131 started on 2016-07-02 04:02\n",
      "Epoch 131 of 550 took 180.897s\n",
      "  training loss:\t\t0.000652\n",
      "  validation loss:\t\t0.006725\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 132 started on 2016-07-02 04:05\n",
      "Epoch 132 of 550 took 180.928s\n",
      "  training loss:\t\t0.000771\n",
      "  validation loss:\t\t0.007199\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 133 started on 2016-07-02 04:08\n",
      "Epoch 133 of 550 took 180.940s\n",
      "  training loss:\t\t0.000738\n",
      "  validation loss:\t\t0.007990\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 134 started on 2016-07-02 04:11\n",
      "Epoch 134 of 550 took 180.941s\n",
      "  training loss:\t\t0.000803\n",
      "  validation loss:\t\t0.008033\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 135 started on 2016-07-02 04:14\n",
      "Epoch 135 of 550 took 180.935s\n",
      "  training loss:\t\t0.000712\n",
      "  validation loss:\t\t0.007217\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 136 started on 2016-07-02 04:17\n",
      "Epoch 136 of 550 took 180.935s\n",
      "  training loss:\t\t0.000661\n",
      "  validation loss:\t\t0.007179\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 137 started on 2016-07-02 04:20\n",
      "Epoch 137 of 550 took 180.966s\n",
      "  training loss:\t\t0.001226\n",
      "  validation loss:\t\t0.008827\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 138 started on 2016-07-02 04:23\n",
      "Epoch 138 of 550 took 180.946s\n",
      "  training loss:\t\t0.000765\n",
      "  validation loss:\t\t0.006814\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 139 started on 2016-07-02 04:26\n",
      "Epoch 139 of 550 took 180.929s\n",
      "  training loss:\t\t0.000744\n",
      "  validation loss:\t\t0.007682\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 140 started on 2016-07-02 04:29\n",
      "Epoch 140 of 550 took 180.968s\n",
      "  training loss:\t\t0.000806\n",
      "  validation loss:\t\t0.008234\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 141 started on 2016-07-02 04:32\n",
      "Epoch 141 of 550 took 180.960s\n",
      "  training loss:\t\t0.000757\n",
      "  validation loss:\t\t0.008543\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 142 started on 2016-07-02 04:35\n",
      "Epoch 142 of 550 took 180.983s\n",
      "  training loss:\t\t0.000751\n",
      "  validation loss:\t\t0.007992\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 143 started on 2016-07-02 04:38\n",
      "Epoch 143 of 550 took 180.953s\n",
      "  training loss:\t\t0.000860\n",
      "  validation loss:\t\t0.007878\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 144 started on 2016-07-02 04:41\n",
      "Epoch 144 of 550 took 180.948s\n",
      "  training loss:\t\t0.000708\n",
      "  validation loss:\t\t0.006714\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 145 started on 2016-07-02 04:44\n",
      "Epoch 145 of 550 took 180.954s\n",
      "  training loss:\t\t0.000763\n",
      "  validation loss:\t\t0.008218\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 146 started on 2016-07-02 04:47\n",
      "Epoch 146 of 550 took 180.965s\n",
      "  training loss:\t\t0.000944\n",
      "  validation loss:\t\t0.008199\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 147 started on 2016-07-02 04:50\n",
      "Epoch 147 of 550 took 180.930s\n",
      "  training loss:\t\t0.000741\n",
      "  validation loss:\t\t0.007689\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 148 started on 2016-07-02 04:53\n",
      "Epoch 148 of 550 took 180.947s\n",
      "  training loss:\t\t0.000827\n",
      "  validation loss:\t\t0.012198\n",
      "  validation accuracy:\t\t99.79 %\n",
      "Epoch 149 started on 2016-07-02 04:56\n",
      "Epoch 149 of 550 took 180.948s\n",
      "  training loss:\t\t0.000662\n",
      "  validation loss:\t\t0.008234\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 150 started on 2016-07-02 04:59\n",
      "Epoch 150 of 550 took 180.951s\n",
      "  training loss:\t\t0.001116\n",
      "  validation loss:\t\t0.006639\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 151 started on 2016-07-02 05:02\n",
      "Epoch 151 of 550 took 180.949s\n",
      "  training loss:\t\t0.001109\n",
      "  validation loss:\t\t0.008029\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 152 started on 2016-07-02 05:05\n",
      "Epoch 152 of 550 took 180.895s\n",
      "  training loss:\t\t0.000638\n",
      "  validation loss:\t\t0.007202\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 153 started on 2016-07-02 05:08\n",
      "Epoch 153 of 550 took 180.905s\n",
      "  training loss:\t\t0.000807\n",
      "  validation loss:\t\t0.006830\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 154 started on 2016-07-02 05:11\n",
      "Epoch 154 of 550 took 180.895s\n",
      "  training loss:\t\t0.000735\n",
      "  validation loss:\t\t0.007117\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 155 started on 2016-07-02 05:14\n",
      "Epoch 155 of 550 took 180.919s\n",
      "  training loss:\t\t0.000851\n",
      "  validation loss:\t\t0.006831\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 156 started on 2016-07-02 05:17\n",
      "Epoch 156 of 550 took 180.898s\n",
      "  training loss:\t\t0.000631\n",
      "  validation loss:\t\t0.007161\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 157 started on 2016-07-02 05:20\n",
      "Epoch 157 of 550 took 180.911s\n",
      "  training loss:\t\t0.000573\n",
      "  validation loss:\t\t0.007759\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 158 started on 2016-07-02 05:23\n",
      "Epoch 158 of 550 took 180.919s\n",
      "  training loss:\t\t0.000575\n",
      "  validation loss:\t\t0.007200\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 159 started on 2016-07-02 05:26\n",
      "Epoch 159 of 550 took 180.894s\n",
      "  training loss:\t\t0.000521\n",
      "  validation loss:\t\t0.008714\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 160 started on 2016-07-02 05:29\n",
      "Epoch 160 of 550 took 180.928s\n",
      "  training loss:\t\t0.000533\n",
      "  validation loss:\t\t0.009192\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 161 started on 2016-07-02 05:32\n",
      "Epoch 161 of 550 took 180.933s\n",
      "  training loss:\t\t0.000673\n",
      "  validation loss:\t\t0.007923\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 162 started on 2016-07-02 05:35\n",
      "Epoch 162 of 550 took 180.923s\n",
      "  training loss:\t\t0.000760\n",
      "  validation loss:\t\t0.007681\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 163 started on 2016-07-02 05:38\n",
      "Epoch 163 of 550 took 180.908s\n",
      "  training loss:\t\t0.000588\n",
      "  validation loss:\t\t0.008324\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 164 started on 2016-07-02 05:41\n",
      "Epoch 164 of 550 took 180.911s\n",
      "  training loss:\t\t0.000815\n",
      "  validation loss:\t\t0.009660\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 165 started on 2016-07-02 05:44\n",
      "Epoch 165 of 550 took 180.942s\n",
      "  training loss:\t\t0.000780\n",
      "  validation loss:\t\t0.007232\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 166 started on 2016-07-02 05:47\n",
      "Epoch 166 of 550 took 180.909s\n",
      "  training loss:\t\t0.000609\n",
      "  validation loss:\t\t0.007542\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 167 started on 2016-07-02 05:50\n",
      "Epoch 167 of 550 took 180.914s\n",
      "  training loss:\t\t0.000663\n",
      "  validation loss:\t\t0.008128\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 168 started on 2016-07-02 05:53\n",
      "Epoch 168 of 550 took 180.932s\n",
      "  training loss:\t\t0.000494\n",
      "  validation loss:\t\t0.007025\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 169 started on 2016-07-02 05:56\n",
      "Epoch 169 of 550 took 180.947s\n",
      "  training loss:\t\t0.000773\n",
      "  validation loss:\t\t0.008379\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 170 started on 2016-07-02 05:59\n",
      "Epoch 170 of 550 took 180.962s\n",
      "  training loss:\t\t0.000646\n",
      "  validation loss:\t\t0.007203\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 171 started on 2016-07-02 06:02\n",
      "Epoch 171 of 550 took 180.968s\n",
      "  training loss:\t\t0.000723\n",
      "  validation loss:\t\t0.008251\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 172 started on 2016-07-02 06:05\n",
      "Epoch 172 of 550 took 180.952s\n",
      "  training loss:\t\t0.000549\n",
      "  validation loss:\t\t0.007204\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 173 started on 2016-07-02 06:08\n",
      "Epoch 173 of 550 took 180.976s\n",
      "  training loss:\t\t0.000617\n",
      "  validation loss:\t\t0.007976\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 174 started on 2016-07-02 06:11\n",
      "Epoch 174 of 550 took 180.959s\n",
      "  training loss:\t\t0.000587\n",
      "  validation loss:\t\t0.006708\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 175 started on 2016-07-02 06:14\n",
      "Epoch 175 of 550 took 180.890s\n",
      "  training loss:\t\t0.000578\n",
      "  validation loss:\t\t0.007487\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 176 started on 2016-07-02 06:17\n",
      "Epoch 176 of 550 took 180.930s\n",
      "  training loss:\t\t0.000561\n",
      "  validation loss:\t\t0.009171\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 177 started on 2016-07-02 06:20\n",
      "Epoch 177 of 550 took 180.918s\n",
      "  training loss:\t\t0.000463\n",
      "  validation loss:\t\t0.007589\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 178 started on 2016-07-02 06:23\n",
      "Epoch 178 of 550 took 180.944s\n",
      "  training loss:\t\t0.000678\n",
      "  validation loss:\t\t0.008402\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 179 started on 2016-07-02 06:26\n",
      "Epoch 179 of 550 took 180.939s\n",
      "  training loss:\t\t0.000780\n",
      "  validation loss:\t\t0.008030\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 180 started on 2016-07-02 06:29\n",
      "Epoch 180 of 550 took 180.911s\n",
      "  training loss:\t\t0.000473\n",
      "  validation loss:\t\t0.006434\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 181 started on 2016-07-02 06:32\n",
      "Epoch 181 of 550 took 180.930s\n",
      "  training loss:\t\t0.000416\n",
      "  validation loss:\t\t0.007837\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 182 started on 2016-07-02 06:35\n",
      "Epoch 182 of 550 took 180.901s\n",
      "  training loss:\t\t0.000648\n",
      "  validation loss:\t\t0.006162\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 183 started on 2016-07-02 06:38\n",
      "Epoch 183 of 550 took 180.935s\n",
      "  training loss:\t\t0.000552\n",
      "  validation loss:\t\t0.007421\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 184 started on 2016-07-02 06:41\n",
      "Epoch 184 of 550 took 180.923s\n",
      "  training loss:\t\t0.000823\n",
      "  validation loss:\t\t0.009393\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 185 started on 2016-07-02 06:44\n",
      "Epoch 185 of 550 took 180.943s\n",
      "  training loss:\t\t0.000669\n",
      "  validation loss:\t\t0.008788\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 186 started on 2016-07-02 06:47\n",
      "Epoch 186 of 550 took 180.964s\n",
      "  training loss:\t\t0.000612\n",
      "  validation loss:\t\t0.008207\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 187 started on 2016-07-02 06:50\n",
      "Epoch 187 of 550 took 180.931s\n",
      "  training loss:\t\t0.000713\n",
      "  validation loss:\t\t0.007673\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 188 started on 2016-07-02 06:53\n",
      "Epoch 188 of 550 took 180.930s\n",
      "  training loss:\t\t0.000610\n",
      "  validation loss:\t\t0.008788\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 189 started on 2016-07-02 06:56\n",
      "Epoch 189 of 550 took 180.937s\n",
      "  training loss:\t\t0.000548\n",
      "  validation loss:\t\t0.010450\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 190 started on 2016-07-02 06:59\n",
      "Epoch 190 of 550 took 180.955s\n",
      "  training loss:\t\t0.000497\n",
      "  validation loss:\t\t0.007955\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 191 started on 2016-07-02 07:02\n",
      "Epoch 191 of 550 took 180.985s\n",
      "  training loss:\t\t0.000670\n",
      "  validation loss:\t\t0.008372\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 192 started on 2016-07-02 07:06\n",
      "Epoch 192 of 550 took 180.927s\n",
      "  training loss:\t\t0.000630\n",
      "  validation loss:\t\t0.007473\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 193 started on 2016-07-02 07:09\n",
      "Epoch 193 of 550 took 180.939s\n",
      "  training loss:\t\t0.000489\n",
      "  validation loss:\t\t0.007048\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 194 started on 2016-07-02 07:12\n",
      "Epoch 194 of 550 took 180.956s\n",
      "  training loss:\t\t0.000537\n",
      "  validation loss:\t\t0.007709\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 195 started on 2016-07-02 07:15\n",
      "Epoch 195 of 550 took 180.948s\n",
      "  training loss:\t\t0.000621\n",
      "  validation loss:\t\t0.009488\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 196 started on 2016-07-02 07:18\n",
      "Epoch 196 of 550 took 180.889s\n",
      "  training loss:\t\t0.000542\n",
      "  validation loss:\t\t0.009542\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 197 started on 2016-07-02 07:21\n",
      "Epoch 197 of 550 took 180.936s\n",
      "  training loss:\t\t0.000564\n",
      "  validation loss:\t\t0.009593\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 198 started on 2016-07-02 07:24\n",
      "Epoch 198 of 550 took 180.918s\n",
      "  training loss:\t\t0.000499\n",
      "  validation loss:\t\t0.010210\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 199 started on 2016-07-02 07:27\n",
      "Epoch 199 of 550 took 180.911s\n",
      "  training loss:\t\t0.000671\n",
      "  validation loss:\t\t0.008010\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 200 started on 2016-07-02 07:30\n",
      "Epoch 200 of 550 took 180.953s\n",
      "  training loss:\t\t0.000446\n",
      "  validation loss:\t\t0.009488\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 201 started on 2016-07-02 07:33\n",
      "Epoch 201 of 550 took 180.933s\n",
      "  training loss:\t\t0.000526\n",
      "  validation loss:\t\t0.008838\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 202 started on 2016-07-02 07:36\n",
      "Epoch 202 of 550 took 180.940s\n",
      "  training loss:\t\t0.000420\n",
      "  validation loss:\t\t0.008033\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 203 started on 2016-07-02 07:39\n",
      "Epoch 203 of 550 took 180.938s\n",
      "  training loss:\t\t0.000335\n",
      "  validation loss:\t\t0.007746\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 204 started on 2016-07-02 07:42\n",
      "Epoch 204 of 550 took 180.950s\n",
      "  training loss:\t\t0.000553\n",
      "  validation loss:\t\t0.008316\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 205 started on 2016-07-02 07:45\n",
      "Epoch 205 of 550 took 180.948s\n",
      "  training loss:\t\t0.000493\n",
      "  validation loss:\t\t0.008584\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 206 started on 2016-07-02 07:48\n",
      "Epoch 206 of 550 took 180.958s\n",
      "  training loss:\t\t0.000467\n",
      "  validation loss:\t\t0.008188\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 207 started on 2016-07-02 07:51\n",
      "Epoch 207 of 550 took 180.926s\n",
      "  training loss:\t\t0.000608\n",
      "  validation loss:\t\t0.006930\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 208 started on 2016-07-02 07:54\n",
      "Epoch 208 of 550 took 180.894s\n",
      "  training loss:\t\t0.000677\n",
      "  validation loss:\t\t0.009571\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 209 started on 2016-07-02 07:57\n",
      "Epoch 209 of 550 took 180.927s\n",
      "  training loss:\t\t0.000527\n",
      "  validation loss:\t\t0.007714\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 210 started on 2016-07-02 08:00\n",
      "Epoch 210 of 550 took 180.932s\n",
      "  training loss:\t\t0.000544\n",
      "  validation loss:\t\t0.006890\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 211 started on 2016-07-02 08:03\n",
      "Epoch 211 of 550 took 180.918s\n",
      "  training loss:\t\t0.000516\n",
      "  validation loss:\t\t0.008183\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 212 started on 2016-07-02 08:06\n",
      "Epoch 212 of 550 took 180.905s\n",
      "  training loss:\t\t0.000307\n",
      "  validation loss:\t\t0.007887\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 213 started on 2016-07-02 08:09\n",
      "Epoch 213 of 550 took 180.931s\n",
      "  training loss:\t\t0.000355\n",
      "  validation loss:\t\t0.009296\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 214 started on 2016-07-02 08:12\n",
      "Epoch 214 of 550 took 180.904s\n",
      "  training loss:\t\t0.000580\n",
      "  validation loss:\t\t0.008065\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 215 started on 2016-07-02 08:15\n",
      "Epoch 215 of 550 took 180.915s\n",
      "  training loss:\t\t0.000452\n",
      "  validation loss:\t\t0.008934\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 216 started on 2016-07-02 08:18\n",
      "Epoch 216 of 550 took 180.943s\n",
      "  training loss:\t\t0.000325\n",
      "  validation loss:\t\t0.009209\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 217 started on 2016-07-02 08:21\n",
      "Epoch 217 of 550 took 180.926s\n",
      "  training loss:\t\t0.000565\n",
      "  validation loss:\t\t0.010977\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 218 started on 2016-07-02 08:24\n",
      "Epoch 218 of 550 took 180.951s\n",
      "  training loss:\t\t0.000797\n",
      "  validation loss:\t\t0.007912\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 219 started on 2016-07-02 08:27\n",
      "Epoch 219 of 550 took 180.914s\n",
      "  training loss:\t\t0.000440\n",
      "  validation loss:\t\t0.007438\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 220 started on 2016-07-02 08:30\n",
      "Epoch 220 of 550 took 180.885s\n",
      "  training loss:\t\t0.000482\n",
      "  validation loss:\t\t0.010507\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 221 started on 2016-07-02 08:33\n",
      "Epoch 221 of 550 took 180.941s\n",
      "  training loss:\t\t0.000358\n",
      "  validation loss:\t\t0.007279\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 222 started on 2016-07-02 08:36\n",
      "Epoch 222 of 550 took 180.939s\n",
      "  training loss:\t\t0.000462\n",
      "  validation loss:\t\t0.008428\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 223 started on 2016-07-02 08:39\n",
      "Epoch 223 of 550 took 180.928s\n",
      "  training loss:\t\t0.000503\n",
      "  validation loss:\t\t0.008603\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 224 started on 2016-07-02 08:42\n",
      "Epoch 224 of 550 took 180.876s\n",
      "  training loss:\t\t0.000380\n",
      "  validation loss:\t\t0.011234\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 225 started on 2016-07-02 08:45\n",
      "Epoch 225 of 550 took 180.896s\n",
      "  training loss:\t\t0.000444\n",
      "  validation loss:\t\t0.007985\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 226 started on 2016-07-02 08:48\n",
      "Epoch 226 of 550 took 180.920s\n",
      "  training loss:\t\t0.000399\n",
      "  validation loss:\t\t0.006703\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 227 started on 2016-07-02 08:51\n",
      "Epoch 227 of 550 took 180.908s\n",
      "  training loss:\t\t0.000327\n",
      "  validation loss:\t\t0.008661\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 228 started on 2016-07-02 08:54\n",
      "Epoch 228 of 550 took 180.920s\n",
      "  training loss:\t\t0.000466\n",
      "  validation loss:\t\t0.006972\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 229 started on 2016-07-02 08:57\n",
      "Epoch 229 of 550 took 180.915s\n",
      "  training loss:\t\t0.000427\n",
      "  validation loss:\t\t0.009233\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 230 started on 2016-07-02 09:00\n",
      "Epoch 230 of 550 took 180.904s\n",
      "  training loss:\t\t0.000344\n",
      "  validation loss:\t\t0.006784\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 231 started on 2016-07-02 09:03\n",
      "Epoch 231 of 550 took 180.919s\n",
      "  training loss:\t\t0.000593\n",
      "  validation loss:\t\t0.008651\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 232 started on 2016-07-02 09:06\n",
      "Epoch 232 of 550 took 180.893s\n",
      "  training loss:\t\t0.000460\n",
      "  validation loss:\t\t0.009373\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 233 started on 2016-07-02 09:09\n",
      "Epoch 233 of 550 took 180.909s\n",
      "  training loss:\t\t0.000311\n",
      "  validation loss:\t\t0.009037\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 234 started on 2016-07-02 09:12\n",
      "Epoch 234 of 550 took 180.911s\n",
      "  training loss:\t\t0.000650\n",
      "  validation loss:\t\t0.010925\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 235 started on 2016-07-02 09:15\n",
      "Epoch 235 of 550 took 180.889s\n",
      "  training loss:\t\t0.000532\n",
      "  validation loss:\t\t0.009648\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 236 started on 2016-07-02 09:18\n",
      "Epoch 236 of 550 took 180.897s\n",
      "  training loss:\t\t0.000524\n",
      "  validation loss:\t\t0.010263\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 237 started on 2016-07-02 09:21\n",
      "Epoch 237 of 550 took 180.893s\n",
      "  training loss:\t\t0.000423\n",
      "  validation loss:\t\t0.007322\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 238 started on 2016-07-02 09:24\n",
      "Epoch 238 of 550 took 180.875s\n",
      "  training loss:\t\t0.000416\n",
      "  validation loss:\t\t0.006690\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 239 started on 2016-07-02 09:27\n",
      "Epoch 239 of 550 took 180.878s\n",
      "  training loss:\t\t0.000425\n",
      "  validation loss:\t\t0.007491\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 240 started on 2016-07-02 09:30\n",
      "Epoch 240 of 550 took 180.877s\n",
      "  training loss:\t\t0.000700\n",
      "  validation loss:\t\t0.008739\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 241 started on 2016-07-02 09:33\n",
      "Epoch 241 of 550 took 180.925s\n",
      "  training loss:\t\t0.000376\n",
      "  validation loss:\t\t0.008756\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 242 started on 2016-07-02 09:36\n",
      "Epoch 242 of 550 took 180.935s\n",
      "  training loss:\t\t0.000355\n",
      "  validation loss:\t\t0.008464\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 243 started on 2016-07-02 09:39\n",
      "Epoch 243 of 550 took 180.889s\n",
      "  training loss:\t\t0.000509\n",
      "  validation loss:\t\t0.008321\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 244 started on 2016-07-02 09:42\n",
      "Epoch 244 of 550 took 180.877s\n",
      "  training loss:\t\t0.000466\n",
      "  validation loss:\t\t0.009159\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 245 started on 2016-07-02 09:45\n",
      "Epoch 245 of 550 took 180.883s\n",
      "  training loss:\t\t0.000443\n",
      "  validation loss:\t\t0.008627\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 246 started on 2016-07-02 09:48\n",
      "Epoch 246 of 550 took 180.941s\n",
      "  training loss:\t\t0.000406\n",
      "  validation loss:\t\t0.007578\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 247 started on 2016-07-02 09:51\n",
      "Epoch 247 of 550 took 180.871s\n",
      "  training loss:\t\t0.000338\n",
      "  validation loss:\t\t0.008279\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 248 started on 2016-07-02 09:54\n",
      "Epoch 248 of 550 took 180.870s\n",
      "  training loss:\t\t0.000312\n",
      "  validation loss:\t\t0.007583\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 249 started on 2016-07-02 09:57\n",
      "Epoch 249 of 550 took 180.856s\n",
      "  training loss:\t\t0.000326\n",
      "  validation loss:\t\t0.006649\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 250 started on 2016-07-02 10:00\n",
      "Epoch 250 of 550 took 180.852s\n",
      "  training loss:\t\t0.000318\n",
      "  validation loss:\t\t0.006610\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 251 started on 2016-07-02 10:03\n",
      "Epoch 251 of 550 took 180.889s\n",
      "  training loss:\t\t0.000349\n",
      "  validation loss:\t\t0.007189\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 252 started on 2016-07-02 10:06\n",
      "Epoch 252 of 550 took 180.901s\n",
      "  training loss:\t\t0.000351\n",
      "  validation loss:\t\t0.008122\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 253 started on 2016-07-02 10:09\n",
      "Epoch 253 of 550 took 180.883s\n",
      "  training loss:\t\t0.000354\n",
      "  validation loss:\t\t0.010078\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 254 started on 2016-07-02 10:12\n",
      "Epoch 254 of 550 took 180.902s\n",
      "  training loss:\t\t0.000271\n",
      "  validation loss:\t\t0.005882\n",
      "  validation accuracy:\t\t99.90 %\n",
      "Epoch 255 started on 2016-07-02 10:15\n",
      "Epoch 255 of 550 took 180.931s\n",
      "  training loss:\t\t0.000726\n",
      "  validation loss:\t\t0.007690\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 256 started on 2016-07-02 10:18\n",
      "Epoch 256 of 550 took 180.884s\n",
      "  training loss:\t\t0.000508\n",
      "  validation loss:\t\t0.006633\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 257 started on 2016-07-02 10:21\n",
      "Epoch 257 of 550 took 180.914s\n",
      "  training loss:\t\t0.000410\n",
      "  validation loss:\t\t0.007242\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 258 started on 2016-07-02 10:25\n",
      "Epoch 258 of 550 took 180.911s\n",
      "  training loss:\t\t0.000550\n",
      "  validation loss:\t\t0.008468\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 259 started on 2016-07-02 10:28\n",
      "Epoch 259 of 550 took 180.931s\n",
      "  training loss:\t\t0.000392\n",
      "  validation loss:\t\t0.008259\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 260 started on 2016-07-02 10:31\n",
      "Epoch 260 of 550 took 180.906s\n",
      "  training loss:\t\t0.000342\n",
      "  validation loss:\t\t0.009027\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 261 started on 2016-07-02 10:34\n",
      "Epoch 261 of 550 took 180.896s\n",
      "  training loss:\t\t0.000495\n",
      "  validation loss:\t\t0.006502\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 262 started on 2016-07-02 10:37\n",
      "Epoch 262 of 550 took 180.902s\n",
      "  training loss:\t\t0.000379\n",
      "  validation loss:\t\t0.008136\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 263 started on 2016-07-02 10:40\n",
      "Epoch 263 of 550 took 180.905s\n",
      "  training loss:\t\t0.000410\n",
      "  validation loss:\t\t0.007194\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 264 started on 2016-07-02 10:43\n",
      "Epoch 264 of 550 took 180.917s\n",
      "  training loss:\t\t0.000458\n",
      "  validation loss:\t\t0.011549\n",
      "  validation accuracy:\t\t99.81 %\n",
      "Epoch 265 started on 2016-07-02 10:46\n",
      "Epoch 265 of 550 took 180.885s\n",
      "  training loss:\t\t0.000367\n",
      "  validation loss:\t\t0.006875\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 266 started on 2016-07-02 10:49\n",
      "Epoch 266 of 550 took 180.917s\n",
      "  training loss:\t\t0.000228\n",
      "  validation loss:\t\t0.007221\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 267 started on 2016-07-02 10:52\n",
      "Epoch 267 of 550 took 180.885s\n",
      "  training loss:\t\t0.000248\n",
      "  validation loss:\t\t0.007637\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 268 started on 2016-07-02 10:55\n",
      "Epoch 268 of 550 took 180.894s\n",
      "  training loss:\t\t0.000395\n",
      "  validation loss:\t\t0.007497\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 269 started on 2016-07-02 10:58\n",
      "Epoch 269 of 550 took 180.918s\n",
      "  training loss:\t\t0.000603\n",
      "  validation loss:\t\t0.009199\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 270 started on 2016-07-02 11:01\n",
      "Epoch 270 of 550 took 180.857s\n",
      "  training loss:\t\t0.000418\n",
      "  validation loss:\t\t0.008905\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 271 started on 2016-07-02 11:04\n",
      "Epoch 271 of 550 took 180.844s\n",
      "  training loss:\t\t0.000337\n",
      "  validation loss:\t\t0.009346\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 272 started on 2016-07-02 11:07\n",
      "Epoch 272 of 550 took 180.857s\n",
      "  training loss:\t\t0.000459\n",
      "  validation loss:\t\t0.006879\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 273 started on 2016-07-02 11:10\n",
      "Epoch 273 of 550 took 180.861s\n",
      "  training loss:\t\t0.000396\n",
      "  validation loss:\t\t0.014398\n",
      "  validation accuracy:\t\t99.77 %\n",
      "Epoch 274 started on 2016-07-02 11:13\n",
      "Epoch 274 of 550 took 180.885s\n",
      "  training loss:\t\t0.000475\n",
      "  validation loss:\t\t0.006556\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 275 started on 2016-07-02 11:16\n",
      "Epoch 275 of 550 took 180.938s\n",
      "  training loss:\t\t0.000283\n",
      "  validation loss:\t\t0.007506\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 276 started on 2016-07-02 11:19\n",
      "Epoch 276 of 550 took 180.894s\n",
      "  training loss:\t\t0.000401\n",
      "  validation loss:\t\t0.006819\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 277 started on 2016-07-02 11:22\n",
      "Epoch 277 of 550 took 180.905s\n",
      "  training loss:\t\t0.000281\n",
      "  validation loss:\t\t0.007398\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 278 started on 2016-07-02 11:25\n",
      "Epoch 278 of 550 took 180.892s\n",
      "  training loss:\t\t0.000334\n",
      "  validation loss:\t\t0.008705\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 279 started on 2016-07-02 11:28\n",
      "Epoch 279 of 550 took 180.859s\n",
      "  training loss:\t\t0.000608\n",
      "  validation loss:\t\t0.007960\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 280 started on 2016-07-02 11:31\n",
      "Epoch 280 of 550 took 180.866s\n",
      "  training loss:\t\t0.000289\n",
      "  validation loss:\t\t0.008866\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 281 started on 2016-07-02 11:34\n",
      "Epoch 281 of 550 took 180.846s\n",
      "  training loss:\t\t0.000331\n",
      "  validation loss:\t\t0.007313\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 282 started on 2016-07-02 11:37\n",
      "Epoch 282 of 550 took 180.857s\n",
      "  training loss:\t\t0.000357\n",
      "  validation loss:\t\t0.007273\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 283 started on 2016-07-02 11:40\n",
      "Epoch 283 of 550 took 180.870s\n",
      "  training loss:\t\t0.000356\n",
      "  validation loss:\t\t0.007725\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 284 started on 2016-07-02 11:43\n",
      "Epoch 284 of 550 took 180.880s\n",
      "  training loss:\t\t0.000282\n",
      "  validation loss:\t\t0.007543\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 285 started on 2016-07-02 11:46\n",
      "Epoch 285 of 550 took 180.882s\n",
      "  training loss:\t\t0.000443\n",
      "  validation loss:\t\t0.008050\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 286 started on 2016-07-02 11:49\n",
      "Epoch 286 of 550 took 180.900s\n",
      "  training loss:\t\t0.000363\n",
      "  validation loss:\t\t0.007917\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 287 started on 2016-07-02 11:52\n",
      "Epoch 287 of 550 took 180.907s\n",
      "  training loss:\t\t0.000234\n",
      "  validation loss:\t\t0.008633\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 288 started on 2016-07-02 11:55\n",
      "Epoch 288 of 550 took 180.893s\n",
      "  training loss:\t\t0.000284\n",
      "  validation loss:\t\t0.008626\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 289 started on 2016-07-02 11:58\n",
      "Epoch 289 of 550 took 180.898s\n",
      "  training loss:\t\t0.000177\n",
      "  validation loss:\t\t0.007815\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 290 started on 2016-07-02 12:01\n",
      "Epoch 290 of 550 took 180.883s\n",
      "  training loss:\t\t0.000385\n",
      "  validation loss:\t\t0.010401\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 291 started on 2016-07-02 12:04\n",
      "Epoch 291 of 550 took 180.889s\n",
      "  training loss:\t\t0.000298\n",
      "  validation loss:\t\t0.007947\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 292 started on 2016-07-02 12:07\n",
      "Epoch 292 of 550 took 180.893s\n",
      "  training loss:\t\t0.000595\n",
      "  validation loss:\t\t0.008193\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 293 started on 2016-07-02 12:10\n",
      "Epoch 293 of 550 took 180.945s\n",
      "  training loss:\t\t0.000286\n",
      "  validation loss:\t\t0.008281\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 294 started on 2016-07-02 12:13\n",
      "Epoch 294 of 550 took 180.907s\n",
      "  training loss:\t\t0.000382\n",
      "  validation loss:\t\t0.010245\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 295 started on 2016-07-02 12:16\n",
      "Epoch 295 of 550 took 180.901s\n",
      "  training loss:\t\t0.000314\n",
      "  validation loss:\t\t0.008128\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 296 started on 2016-07-02 12:19\n",
      "Epoch 296 of 550 took 180.889s\n",
      "  training loss:\t\t0.000315\n",
      "  validation loss:\t\t0.007323\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 297 started on 2016-07-02 12:22\n",
      "Epoch 297 of 550 took 180.896s\n",
      "  training loss:\t\t0.000497\n",
      "  validation loss:\t\t0.007462\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 298 started on 2016-07-02 12:25\n",
      "Epoch 298 of 550 took 180.918s\n",
      "  training loss:\t\t0.000453\n",
      "  validation loss:\t\t0.007469\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 299 started on 2016-07-02 12:28\n",
      "Epoch 299 of 550 took 180.917s\n",
      "  training loss:\t\t0.000640\n",
      "  validation loss:\t\t0.007934\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 300 started on 2016-07-02 12:31\n",
      "Epoch 300 of 550 took 180.904s\n",
      "  training loss:\t\t0.000580\n",
      "  validation loss:\t\t0.006851\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 301 started on 2016-07-02 12:34\n",
      "Epoch 301 of 550 took 180.915s\n",
      "  training loss:\t\t0.000324\n",
      "  validation loss:\t\t0.006829\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 302 started on 2016-07-02 12:37\n",
      "Epoch 302 of 550 took 180.941s\n",
      "  training loss:\t\t0.000386\n",
      "  validation loss:\t\t0.007857\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 303 started on 2016-07-02 12:40\n",
      "Epoch 303 of 550 took 180.906s\n",
      "  training loss:\t\t0.000318\n",
      "  validation loss:\t\t0.006737\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 304 started on 2016-07-02 12:43\n",
      "Epoch 304 of 550 took 180.903s\n",
      "  training loss:\t\t0.000254\n",
      "  validation loss:\t\t0.007599\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 305 started on 2016-07-02 12:46\n",
      "Epoch 305 of 550 took 180.908s\n",
      "  training loss:\t\t0.000473\n",
      "  validation loss:\t\t0.009396\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 306 started on 2016-07-02 12:49\n",
      "Epoch 306 of 550 took 180.907s\n",
      "  training loss:\t\t0.000538\n",
      "  validation loss:\t\t0.011204\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 307 started on 2016-07-02 12:52\n",
      "Epoch 307 of 550 took 180.921s\n",
      "  training loss:\t\t0.000255\n",
      "  validation loss:\t\t0.008835\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 308 started on 2016-07-02 12:55\n",
      "Epoch 308 of 550 took 180.942s\n",
      "  training loss:\t\t0.000367\n",
      "  validation loss:\t\t0.007216\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 309 started on 2016-07-02 12:58\n",
      "Epoch 309 of 550 took 180.929s\n",
      "  training loss:\t\t0.000292\n",
      "  validation loss:\t\t0.007143\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 310 started on 2016-07-02 13:01\n",
      "Epoch 310 of 550 took 180.927s\n",
      "  training loss:\t\t0.000515\n",
      "  validation loss:\t\t0.008525\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 311 started on 2016-07-02 13:04\n",
      "Epoch 311 of 550 took 180.953s\n",
      "  training loss:\t\t0.000288\n",
      "  validation loss:\t\t0.007296\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 312 started on 2016-07-02 13:07\n",
      "Epoch 312 of 550 took 180.981s\n",
      "  training loss:\t\t0.000280\n",
      "  validation loss:\t\t0.007137\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 313 started on 2016-07-02 13:10\n",
      "Epoch 313 of 550 took 180.946s\n",
      "  training loss:\t\t0.000162\n",
      "  validation loss:\t\t0.007749\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 314 started on 2016-07-02 13:13\n",
      "Epoch 314 of 550 took 180.936s\n",
      "  training loss:\t\t0.000375\n",
      "  validation loss:\t\t0.007895\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 315 started on 2016-07-02 13:16\n",
      "Epoch 315 of 550 took 180.935s\n",
      "  training loss:\t\t0.000241\n",
      "  validation loss:\t\t0.007506\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 316 started on 2016-07-02 13:19\n",
      "Epoch 316 of 550 took 180.938s\n",
      "  training loss:\t\t0.000319\n",
      "  validation loss:\t\t0.006858\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 317 started on 2016-07-02 13:22\n",
      "Epoch 317 of 550 took 180.905s\n",
      "  training loss:\t\t0.000305\n",
      "  validation loss:\t\t0.007404\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 318 started on 2016-07-02 13:25\n",
      "Epoch 318 of 550 took 180.910s\n",
      "  training loss:\t\t0.000238\n",
      "  validation loss:\t\t0.007273\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 319 started on 2016-07-02 13:28\n",
      "Epoch 319 of 550 took 180.906s\n",
      "  training loss:\t\t0.000234\n",
      "  validation loss:\t\t0.006727\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 320 started on 2016-07-02 13:31\n",
      "Epoch 320 of 550 took 180.909s\n",
      "  training loss:\t\t0.000439\n",
      "  validation loss:\t\t0.007799\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 321 started on 2016-07-02 13:34\n",
      "Epoch 321 of 550 took 180.889s\n",
      "  training loss:\t\t0.000281\n",
      "  validation loss:\t\t0.007592\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 322 started on 2016-07-02 13:37\n",
      "Epoch 322 of 550 took 180.891s\n",
      "  training loss:\t\t0.000288\n",
      "  validation loss:\t\t0.007960\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 323 started on 2016-07-02 13:40\n",
      "Epoch 323 of 550 took 180.899s\n",
      "  training loss:\t\t0.000193\n",
      "  validation loss:\t\t0.007065\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 324 started on 2016-07-02 13:44\n",
      "Epoch 324 of 550 took 180.909s\n",
      "  training loss:\t\t0.000189\n",
      "  validation loss:\t\t0.008237\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 325 started on 2016-07-02 13:47\n",
      "Epoch 325 of 550 took 180.876s\n",
      "  training loss:\t\t0.000225\n",
      "  validation loss:\t\t0.009440\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 326 started on 2016-07-02 13:50\n",
      "Epoch 326 of 550 took 180.874s\n",
      "  training loss:\t\t0.000241\n",
      "  validation loss:\t\t0.007910\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 327 started on 2016-07-02 13:53\n",
      "Epoch 327 of 550 took 180.909s\n",
      "  training loss:\t\t0.000329\n",
      "  validation loss:\t\t0.007464\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 328 started on 2016-07-02 13:56\n",
      "Epoch 328 of 550 took 180.889s\n",
      "  training loss:\t\t0.000224\n",
      "  validation loss:\t\t0.007983\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 329 started on 2016-07-02 13:59\n",
      "Epoch 329 of 550 took 180.872s\n",
      "  training loss:\t\t0.000203\n",
      "  validation loss:\t\t0.008043\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 330 started on 2016-07-02 14:02\n",
      "Epoch 330 of 550 took 180.864s\n",
      "  training loss:\t\t0.000188\n",
      "  validation loss:\t\t0.009115\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 331 started on 2016-07-02 14:05\n",
      "Epoch 331 of 550 took 180.886s\n",
      "  training loss:\t\t0.000184\n",
      "  validation loss:\t\t0.008510\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 332 started on 2016-07-02 14:08\n",
      "Epoch 332 of 550 took 180.888s\n",
      "  training loss:\t\t0.000232\n",
      "  validation loss:\t\t0.008355\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 333 started on 2016-07-02 14:11\n",
      "Epoch 333 of 550 took 180.894s\n",
      "  training loss:\t\t0.000257\n",
      "  validation loss:\t\t0.006418\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 334 started on 2016-07-02 14:14\n",
      "Epoch 334 of 550 took 180.906s\n",
      "  training loss:\t\t0.000224\n",
      "  validation loss:\t\t0.007714\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 335 started on 2016-07-02 14:17\n",
      "Epoch 335 of 550 took 180.864s\n",
      "  training loss:\t\t0.000214\n",
      "  validation loss:\t\t0.007478\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 336 started on 2016-07-02 14:20\n",
      "Epoch 336 of 550 took 180.894s\n",
      "  training loss:\t\t0.000431\n",
      "  validation loss:\t\t0.010355\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 337 started on 2016-07-02 14:23\n",
      "Epoch 337 of 550 took 180.907s\n",
      "  training loss:\t\t0.000279\n",
      "  validation loss:\t\t0.009718\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 338 started on 2016-07-02 14:26\n",
      "Epoch 338 of 550 took 180.885s\n",
      "  training loss:\t\t0.000227\n",
      "  validation loss:\t\t0.007131\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 339 started on 2016-07-02 14:29\n",
      "Epoch 339 of 550 took 180.856s\n",
      "  training loss:\t\t0.000296\n",
      "  validation loss:\t\t0.007396\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 340 started on 2016-07-02 14:32\n",
      "Epoch 340 of 550 took 180.858s\n",
      "  training loss:\t\t0.000259\n",
      "  validation loss:\t\t0.009376\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 341 started on 2016-07-02 14:35\n",
      "Epoch 341 of 550 took 180.871s\n",
      "  training loss:\t\t0.000397\n",
      "  validation loss:\t\t0.007867\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 342 started on 2016-07-02 14:38\n",
      "Epoch 342 of 550 took 180.921s\n",
      "  training loss:\t\t0.000483\n",
      "  validation loss:\t\t0.008552\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 343 started on 2016-07-02 14:41\n",
      "Epoch 343 of 550 took 180.880s\n",
      "  training loss:\t\t0.000400\n",
      "  validation loss:\t\t0.007301\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 344 started on 2016-07-02 14:44\n",
      "Epoch 344 of 550 took 180.918s\n",
      "  training loss:\t\t0.000290\n",
      "  validation loss:\t\t0.009359\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 345 started on 2016-07-02 14:47\n",
      "Epoch 345 of 550 took 180.881s\n",
      "  training loss:\t\t0.000292\n",
      "  validation loss:\t\t0.006862\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 346 started on 2016-07-02 14:50\n",
      "Epoch 346 of 550 took 180.855s\n",
      "  training loss:\t\t0.000184\n",
      "  validation loss:\t\t0.007999\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 347 started on 2016-07-02 14:53\n",
      "Epoch 347 of 550 took 180.882s\n",
      "  training loss:\t\t0.000276\n",
      "  validation loss:\t\t0.006811\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 348 started on 2016-07-02 14:56\n",
      "Epoch 348 of 550 took 180.892s\n",
      "  training loss:\t\t0.000145\n",
      "  validation loss:\t\t0.006855\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 349 started on 2016-07-02 14:59\n",
      "Epoch 349 of 550 took 180.887s\n",
      "  training loss:\t\t0.000261\n",
      "  validation loss:\t\t0.009189\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 350 started on 2016-07-02 15:02\n",
      "Epoch 350 of 550 took 180.892s\n",
      "  training loss:\t\t0.000139\n",
      "  validation loss:\t\t0.007337\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 351 started on 2016-07-02 15:05\n",
      "Epoch 351 of 550 took 180.868s\n",
      "  training loss:\t\t0.000227\n",
      "  validation loss:\t\t0.008031\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 352 started on 2016-07-02 15:08\n",
      "Epoch 352 of 550 took 180.918s\n",
      "  training loss:\t\t0.000195\n",
      "  validation loss:\t\t0.007026\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 353 started on 2016-07-02 15:11\n",
      "Epoch 353 of 550 took 180.885s\n",
      "  training loss:\t\t0.000218\n",
      "  validation loss:\t\t0.008924\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 354 started on 2016-07-02 15:14\n",
      "Epoch 354 of 550 took 180.915s\n",
      "  training loss:\t\t0.000239\n",
      "  validation loss:\t\t0.008419\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 355 started on 2016-07-02 15:17\n",
      "Epoch 355 of 550 took 180.899s\n",
      "  training loss:\t\t0.000220\n",
      "  validation loss:\t\t0.010204\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 356 started on 2016-07-02 15:20\n",
      "Epoch 356 of 550 took 180.878s\n",
      "  training loss:\t\t0.000205\n",
      "  validation loss:\t\t0.009336\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 357 started on 2016-07-02 15:23\n",
      "Epoch 357 of 550 took 180.924s\n",
      "  training loss:\t\t0.000317\n",
      "  validation loss:\t\t0.011506\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 358 started on 2016-07-02 15:26\n",
      "Epoch 358 of 550 took 180.886s\n",
      "  training loss:\t\t0.000337\n",
      "  validation loss:\t\t0.009507\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 359 started on 2016-07-02 15:29\n",
      "Epoch 359 of 550 took 180.915s\n",
      "  training loss:\t\t0.000188\n",
      "  validation loss:\t\t0.008512\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 360 started on 2016-07-02 15:32\n",
      "Epoch 360 of 550 took 180.898s\n",
      "  training loss:\t\t0.000147\n",
      "  validation loss:\t\t0.007119\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 361 started on 2016-07-02 15:35\n",
      "Epoch 361 of 550 took 180.863s\n",
      "  training loss:\t\t0.000276\n",
      "  validation loss:\t\t0.007530\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 362 started on 2016-07-02 15:38\n",
      "Epoch 362 of 550 took 180.888s\n",
      "  training loss:\t\t0.000283\n",
      "  validation loss:\t\t0.008057\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 363 started on 2016-07-02 15:41\n",
      "Epoch 363 of 550 took 180.887s\n",
      "  training loss:\t\t0.000149\n",
      "  validation loss:\t\t0.008257\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 364 started on 2016-07-02 15:44\n",
      "Epoch 364 of 550 took 180.873s\n",
      "  training loss:\t\t0.000152\n",
      "  validation loss:\t\t0.008294\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 365 started on 2016-07-02 15:47\n",
      "Epoch 365 of 550 took 180.884s\n",
      "  training loss:\t\t0.000224\n",
      "  validation loss:\t\t0.007661\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 366 started on 2016-07-02 15:50\n",
      "Epoch 366 of 550 took 180.829s\n",
      "  training loss:\t\t0.000238\n",
      "  validation loss:\t\t0.008525\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 367 started on 2016-07-02 15:53\n",
      "Epoch 367 of 550 took 180.883s\n",
      "  training loss:\t\t0.000185\n",
      "  validation loss:\t\t0.008800\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 368 started on 2016-07-02 15:56\n",
      "Epoch 368 of 550 took 180.865s\n",
      "  training loss:\t\t0.000288\n",
      "  validation loss:\t\t0.007769\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 369 started on 2016-07-02 15:59\n",
      "Epoch 369 of 550 took 180.889s\n",
      "  training loss:\t\t0.000370\n",
      "  validation loss:\t\t0.007330\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 370 started on 2016-07-02 16:02\n",
      "Epoch 370 of 550 took 180.904s\n",
      "  training loss:\t\t0.000318\n",
      "  validation loss:\t\t0.008808\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 371 started on 2016-07-02 16:05\n",
      "Epoch 371 of 550 took 180.892s\n",
      "  training loss:\t\t0.000310\n",
      "  validation loss:\t\t0.008468\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 372 started on 2016-07-02 16:08\n",
      "Epoch 372 of 550 took 180.892s\n",
      "  training loss:\t\t0.000244\n",
      "  validation loss:\t\t0.008644\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 373 started on 2016-07-02 16:11\n",
      "Epoch 373 of 550 took 180.881s\n",
      "  training loss:\t\t0.000299\n",
      "  validation loss:\t\t0.009082\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 374 started on 2016-07-02 16:14\n",
      "Epoch 374 of 550 took 180.877s\n",
      "  training loss:\t\t0.000260\n",
      "  validation loss:\t\t0.011889\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 375 started on 2016-07-02 16:17\n",
      "Epoch 375 of 550 took 180.861s\n",
      "  training loss:\t\t0.000473\n",
      "  validation loss:\t\t0.009002\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 376 started on 2016-07-02 16:20\n",
      "Epoch 376 of 550 took 180.867s\n",
      "  training loss:\t\t0.000205\n",
      "  validation loss:\t\t0.010160\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 377 started on 2016-07-02 16:23\n",
      "Epoch 377 of 550 took 180.872s\n",
      "  training loss:\t\t0.000194\n",
      "  validation loss:\t\t0.008962\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 378 started on 2016-07-02 16:26\n",
      "Epoch 378 of 550 took 180.888s\n",
      "  training loss:\t\t0.000231\n",
      "  validation loss:\t\t0.008717\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 379 started on 2016-07-02 16:29\n",
      "Epoch 379 of 550 took 180.916s\n",
      "  training loss:\t\t0.000212\n",
      "  validation loss:\t\t0.008634\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 380 started on 2016-07-02 16:32\n",
      "Epoch 380 of 550 took 180.864s\n",
      "  training loss:\t\t0.000192\n",
      "  validation loss:\t\t0.007602\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 381 started on 2016-07-02 16:35\n",
      "Epoch 381 of 550 took 180.904s\n",
      "  training loss:\t\t0.000216\n",
      "  validation loss:\t\t0.008387\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 382 started on 2016-07-02 16:38\n",
      "Epoch 382 of 550 took 180.907s\n",
      "  training loss:\t\t0.000266\n",
      "  validation loss:\t\t0.008340\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 383 started on 2016-07-02 16:41\n",
      "Epoch 383 of 550 took 180.913s\n",
      "  training loss:\t\t0.000314\n",
      "  validation loss:\t\t0.009127\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 384 started on 2016-07-02 16:44\n",
      "Epoch 384 of 550 took 180.877s\n",
      "  training loss:\t\t0.000288\n",
      "  validation loss:\t\t0.009509\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 385 started on 2016-07-02 16:47\n",
      "Epoch 385 of 550 took 180.888s\n",
      "  training loss:\t\t0.000308\n",
      "  validation loss:\t\t0.007762\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 386 started on 2016-07-02 16:50\n",
      "Epoch 386 of 550 took 180.893s\n",
      "  training loss:\t\t0.000324\n",
      "  validation loss:\t\t0.006874\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 387 started on 2016-07-02 16:53\n",
      "Epoch 387 of 550 took 180.862s\n",
      "  training loss:\t\t0.000227\n",
      "  validation loss:\t\t0.008777\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 388 started on 2016-07-02 16:56\n",
      "Epoch 388 of 550 took 180.847s\n",
      "  training loss:\t\t0.000294\n",
      "  validation loss:\t\t0.008315\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 389 started on 2016-07-02 16:59\n",
      "Epoch 389 of 550 took 180.877s\n",
      "  training loss:\t\t0.000190\n",
      "  validation loss:\t\t0.009824\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 390 started on 2016-07-02 17:02\n",
      "Epoch 390 of 550 took 180.897s\n",
      "  training loss:\t\t0.000434\n",
      "  validation loss:\t\t0.006659\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 391 started on 2016-07-02 17:05\n",
      "Epoch 391 of 550 took 180.909s\n",
      "  training loss:\t\t0.000223\n",
      "  validation loss:\t\t0.008363\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 392 started on 2016-07-02 17:09\n",
      "Epoch 392 of 550 took 180.884s\n",
      "  training loss:\t\t0.000142\n",
      "  validation loss:\t\t0.008816\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 393 started on 2016-07-02 17:12\n",
      "Epoch 393 of 550 took 180.886s\n",
      "  training loss:\t\t0.000270\n",
      "  validation loss:\t\t0.008667\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 394 started on 2016-07-02 17:15\n",
      "Epoch 394 of 550 took 180.862s\n",
      "  training loss:\t\t0.000225\n",
      "  validation loss:\t\t0.008471\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 395 started on 2016-07-02 17:18\n",
      "Epoch 395 of 550 took 180.860s\n",
      "  training loss:\t\t0.000268\n",
      "  validation loss:\t\t0.010717\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 396 started on 2016-07-02 17:21\n",
      "Epoch 396 of 550 took 180.868s\n",
      "  training loss:\t\t0.000351\n",
      "  validation loss:\t\t0.008847\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 397 started on 2016-07-02 17:24\n",
      "Epoch 397 of 550 took 180.873s\n",
      "  training loss:\t\t0.000251\n",
      "  validation loss:\t\t0.008738\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 398 started on 2016-07-02 17:27\n",
      "Epoch 398 of 550 took 180.835s\n",
      "  training loss:\t\t0.000195\n",
      "  validation loss:\t\t0.008144\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 399 started on 2016-07-02 17:30\n",
      "Epoch 399 of 550 took 180.853s\n",
      "  training loss:\t\t0.000182\n",
      "  validation loss:\t\t0.007063\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 400 started on 2016-07-02 17:33\n",
      "Epoch 400 of 550 took 180.895s\n",
      "  training loss:\t\t0.000241\n",
      "  validation loss:\t\t0.008496\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 401 started on 2016-07-02 17:36\n",
      "Epoch 401 of 550 took 180.894s\n",
      "  training loss:\t\t0.000202\n",
      "  validation loss:\t\t0.006583\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 402 started on 2016-07-02 17:39\n",
      "Epoch 402 of 550 took 180.889s\n",
      "  training loss:\t\t0.000146\n",
      "  validation loss:\t\t0.007383\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 403 started on 2016-07-02 17:42\n",
      "Epoch 403 of 550 took 180.880s\n",
      "  training loss:\t\t0.000129\n",
      "  validation loss:\t\t0.009051\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 404 started on 2016-07-02 17:45\n",
      "Epoch 404 of 550 took 180.884s\n",
      "  training loss:\t\t0.000229\n",
      "  validation loss:\t\t0.008234\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 405 started on 2016-07-02 17:48\n",
      "Epoch 405 of 550 took 180.862s\n",
      "  training loss:\t\t0.000228\n",
      "  validation loss:\t\t0.009121\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 406 started on 2016-07-02 17:51\n",
      "Epoch 406 of 550 took 180.886s\n",
      "  training loss:\t\t0.000221\n",
      "  validation loss:\t\t0.008049\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 407 started on 2016-07-02 17:54\n",
      "Epoch 407 of 550 took 180.860s\n",
      "  training loss:\t\t0.000228\n",
      "  validation loss:\t\t0.007656\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 408 started on 2016-07-02 17:57\n",
      "Epoch 408 of 550 took 180.883s\n",
      "  training loss:\t\t0.000139\n",
      "  validation loss:\t\t0.009584\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 409 started on 2016-07-02 18:00\n",
      "Epoch 409 of 550 took 180.876s\n",
      "  training loss:\t\t0.000270\n",
      "  validation loss:\t\t0.008990\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 410 started on 2016-07-02 18:03\n",
      "Epoch 410 of 550 took 180.886s\n",
      "  training loss:\t\t0.000195\n",
      "  validation loss:\t\t0.007294\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 411 started on 2016-07-02 18:06\n",
      "Epoch 411 of 550 took 180.876s\n",
      "  training loss:\t\t0.000265\n",
      "  validation loss:\t\t0.008552\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 412 started on 2016-07-02 18:09\n",
      "Epoch 412 of 550 took 180.888s\n",
      "  training loss:\t\t0.000263\n",
      "  validation loss:\t\t0.009950\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 413 started on 2016-07-02 18:12\n",
      "Epoch 413 of 550 took 180.873s\n",
      "  training loss:\t\t0.000156\n",
      "  validation loss:\t\t0.008873\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 414 started on 2016-07-02 18:15\n",
      "Epoch 414 of 550 took 180.930s\n",
      "  training loss:\t\t0.000146\n",
      "  validation loss:\t\t0.008643\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 415 started on 2016-07-02 18:18\n",
      "Epoch 415 of 550 took 180.908s\n",
      "  training loss:\t\t0.000220\n",
      "  validation loss:\t\t0.008389\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 416 started on 2016-07-02 18:21\n",
      "Epoch 416 of 550 took 180.905s\n",
      "  training loss:\t\t0.000173\n",
      "  validation loss:\t\t0.008975\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 417 started on 2016-07-02 18:24\n",
      "Epoch 417 of 550 took 180.914s\n",
      "  training loss:\t\t0.000216\n",
      "  validation loss:\t\t0.008070\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 418 started on 2016-07-02 18:27\n",
      "Epoch 418 of 550 took 180.898s\n",
      "  training loss:\t\t0.000197\n",
      "  validation loss:\t\t0.008139\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 419 started on 2016-07-02 18:30\n",
      "Epoch 419 of 550 took 180.883s\n",
      "  training loss:\t\t0.000173\n",
      "  validation loss:\t\t0.008166\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 420 started on 2016-07-02 18:33\n",
      "Epoch 420 of 550 took 180.872s\n",
      "  training loss:\t\t0.000376\n",
      "  validation loss:\t\t0.009338\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 421 started on 2016-07-02 18:36\n",
      "Epoch 421 of 550 took 180.871s\n",
      "  training loss:\t\t0.000167\n",
      "  validation loss:\t\t0.008092\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 422 started on 2016-07-02 18:39\n",
      "Epoch 422 of 550 took 180.869s\n",
      "  training loss:\t\t0.000242\n",
      "  validation loss:\t\t0.009572\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 423 started on 2016-07-02 18:42\n",
      "Epoch 423 of 550 took 180.857s\n",
      "  training loss:\t\t0.000332\n",
      "  validation loss:\t\t0.008968\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 424 started on 2016-07-02 18:45\n",
      "Epoch 424 of 550 took 180.857s\n",
      "  training loss:\t\t0.000241\n",
      "  validation loss:\t\t0.008409\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 425 started on 2016-07-02 18:48\n",
      "Epoch 425 of 550 took 180.841s\n",
      "  training loss:\t\t0.000205\n",
      "  validation loss:\t\t0.008241\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 426 started on 2016-07-02 18:51\n",
      "Epoch 426 of 550 took 180.872s\n",
      "  training loss:\t\t0.000152\n",
      "  validation loss:\t\t0.008602\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 427 started on 2016-07-02 18:54\n",
      "Epoch 427 of 550 took 180.864s\n",
      "  training loss:\t\t0.000189\n",
      "  validation loss:\t\t0.008261\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 428 started on 2016-07-02 18:57\n",
      "Epoch 428 of 550 took 180.832s\n",
      "  training loss:\t\t0.000165\n",
      "  validation loss:\t\t0.008389\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 429 started on 2016-07-02 19:00\n",
      "Epoch 429 of 550 took 180.867s\n",
      "  training loss:\t\t0.000167\n",
      "  validation loss:\t\t0.008153\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 430 started on 2016-07-02 19:03\n",
      "Epoch 430 of 550 took 180.850s\n",
      "  training loss:\t\t0.000190\n",
      "  validation loss:\t\t0.006694\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 431 started on 2016-07-02 19:06\n",
      "Epoch 431 of 550 took 180.864s\n",
      "  training loss:\t\t0.000329\n",
      "  validation loss:\t\t0.009411\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 432 started on 2016-07-02 19:09\n",
      "Epoch 432 of 550 took 180.870s\n",
      "  training loss:\t\t0.000197\n",
      "  validation loss:\t\t0.008231\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 433 started on 2016-07-02 19:12\n",
      "Epoch 433 of 550 took 180.844s\n",
      "  training loss:\t\t0.000229\n",
      "  validation loss:\t\t0.010233\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 434 started on 2016-07-02 19:15\n",
      "Epoch 434 of 550 took 180.875s\n",
      "  training loss:\t\t0.000299\n",
      "  validation loss:\t\t0.007361\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 435 started on 2016-07-02 19:18\n",
      "Epoch 435 of 550 took 180.867s\n",
      "  training loss:\t\t0.000204\n",
      "  validation loss:\t\t0.006527\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 436 started on 2016-07-02 19:21\n",
      "Epoch 436 of 550 took 180.862s\n",
      "  training loss:\t\t0.000184\n",
      "  validation loss:\t\t0.008424\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 437 started on 2016-07-02 19:24\n",
      "Epoch 437 of 550 took 180.884s\n",
      "  training loss:\t\t0.000338\n",
      "  validation loss:\t\t0.008740\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 438 started on 2016-07-02 19:27\n",
      "Epoch 438 of 550 took 180.875s\n",
      "  training loss:\t\t0.000313\n",
      "  validation loss:\t\t0.009832\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 439 started on 2016-07-02 19:30\n",
      "Epoch 439 of 550 took 180.916s\n",
      "  training loss:\t\t0.000238\n",
      "  validation loss:\t\t0.008240\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 440 started on 2016-07-02 19:33\n",
      "Epoch 440 of 550 took 180.869s\n",
      "  training loss:\t\t0.000352\n",
      "  validation loss:\t\t0.010597\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 441 started on 2016-07-02 19:36\n",
      "Epoch 441 of 550 took 180.883s\n",
      "  training loss:\t\t0.000222\n",
      "  validation loss:\t\t0.008531\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 442 started on 2016-07-02 19:39\n",
      "Epoch 442 of 550 took 180.903s\n",
      "  training loss:\t\t0.000164\n",
      "  validation loss:\t\t0.009835\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 443 started on 2016-07-02 19:42\n",
      "Epoch 443 of 550 took 180.911s\n",
      "  training loss:\t\t0.000280\n",
      "  validation loss:\t\t0.007766\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 444 started on 2016-07-02 19:45\n",
      "Epoch 444 of 550 took 180.866s\n",
      "  training loss:\t\t0.000225\n",
      "  validation loss:\t\t0.006968\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 445 started on 2016-07-02 19:48\n",
      "Epoch 445 of 550 took 180.879s\n",
      "  training loss:\t\t0.000240\n",
      "  validation loss:\t\t0.008464\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 446 started on 2016-07-02 19:51\n",
      "Epoch 446 of 550 took 180.878s\n",
      "  training loss:\t\t0.000312\n",
      "  validation loss:\t\t0.007880\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 447 started on 2016-07-02 19:54\n",
      "Epoch 447 of 550 took 180.892s\n",
      "  training loss:\t\t0.000246\n",
      "  validation loss:\t\t0.008691\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 448 started on 2016-07-02 19:57\n",
      "Epoch 448 of 550 took 180.929s\n",
      "  training loss:\t\t0.000149\n",
      "  validation loss:\t\t0.008863\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 449 started on 2016-07-02 20:00\n",
      "Epoch 449 of 550 took 180.912s\n",
      "  training loss:\t\t0.000293\n",
      "  validation loss:\t\t0.008546\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 450 started on 2016-07-02 20:03\n",
      "Epoch 450 of 550 took 180.909s\n",
      "  training loss:\t\t0.000143\n",
      "  validation loss:\t\t0.010141\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 451 started on 2016-07-02 20:06\n",
      "Epoch 451 of 550 took 180.904s\n",
      "  training loss:\t\t0.000215\n",
      "  validation loss:\t\t0.007398\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 452 started on 2016-07-02 20:09\n",
      "Epoch 452 of 550 took 180.885s\n",
      "  training loss:\t\t0.000117\n",
      "  validation loss:\t\t0.008189\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 453 started on 2016-07-02 20:12\n",
      "Epoch 453 of 550 took 180.857s\n",
      "  training loss:\t\t0.000129\n",
      "  validation loss:\t\t0.010280\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 454 started on 2016-07-02 20:15\n",
      "Epoch 454 of 550 took 180.868s\n",
      "  training loss:\t\t0.000139\n",
      "  validation loss:\t\t0.008901\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 455 started on 2016-07-02 20:18\n",
      "Epoch 455 of 550 took 180.898s\n",
      "  training loss:\t\t0.000144\n",
      "  validation loss:\t\t0.008179\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 456 started on 2016-07-02 20:21\n",
      "Epoch 456 of 550 took 180.895s\n",
      "  training loss:\t\t0.000145\n",
      "  validation loss:\t\t0.008437\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 457 started on 2016-07-02 20:24\n",
      "Epoch 457 of 550 took 180.883s\n",
      "  training loss:\t\t0.000148\n",
      "  validation loss:\t\t0.009154\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 458 started on 2016-07-02 20:27\n",
      "Epoch 458 of 550 took 180.891s\n",
      "  training loss:\t\t0.000129\n",
      "  validation loss:\t\t0.008597\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 459 started on 2016-07-02 20:30\n",
      "Epoch 459 of 550 took 180.924s\n",
      "  training loss:\t\t0.000109\n",
      "  validation loss:\t\t0.008611\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 460 started on 2016-07-02 20:34\n",
      "Epoch 460 of 550 took 180.917s\n",
      "  training loss:\t\t0.000164\n",
      "  validation loss:\t\t0.007979\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 461 started on 2016-07-02 20:37\n",
      "Epoch 461 of 550 took 180.887s\n",
      "  training loss:\t\t0.000249\n",
      "  validation loss:\t\t0.008470\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 462 started on 2016-07-02 20:40\n",
      "Epoch 462 of 550 took 180.902s\n",
      "  training loss:\t\t0.000305\n",
      "  validation loss:\t\t0.008660\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 463 started on 2016-07-02 20:43\n",
      "Epoch 463 of 550 took 180.890s\n",
      "  training loss:\t\t0.000229\n",
      "  validation loss:\t\t0.007203\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 464 started on 2016-07-02 20:46\n",
      "Epoch 464 of 550 took 180.889s\n",
      "  training loss:\t\t0.000175\n",
      "  validation loss:\t\t0.008944\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 465 started on 2016-07-02 20:49\n",
      "Epoch 465 of 550 took 180.872s\n",
      "  training loss:\t\t0.000307\n",
      "  validation loss:\t\t0.009975\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 466 started on 2016-07-02 20:52\n",
      "Epoch 466 of 550 took 180.891s\n",
      "  training loss:\t\t0.000259\n",
      "  validation loss:\t\t0.009255\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 467 started on 2016-07-02 20:55\n",
      "Epoch 467 of 550 took 180.851s\n",
      "  training loss:\t\t0.000280\n",
      "  validation loss:\t\t0.009331\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 468 started on 2016-07-02 20:58\n",
      "Epoch 468 of 550 took 180.947s\n",
      "  training loss:\t\t0.000239\n",
      "  validation loss:\t\t0.010079\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 469 started on 2016-07-02 21:01\n",
      "Epoch 469 of 550 took 180.911s\n",
      "  training loss:\t\t0.000164\n",
      "  validation loss:\t\t0.008865\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 470 started on 2016-07-02 21:04\n",
      "Epoch 470 of 550 took 180.883s\n",
      "  training loss:\t\t0.000146\n",
      "  validation loss:\t\t0.007758\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 471 started on 2016-07-02 21:07\n",
      "Epoch 471 of 550 took 180.875s\n",
      "  training loss:\t\t0.000141\n",
      "  validation loss:\t\t0.009924\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 472 started on 2016-07-02 21:10\n",
      "Epoch 472 of 550 took 180.872s\n",
      "  training loss:\t\t0.000175\n",
      "  validation loss:\t\t0.009489\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 473 started on 2016-07-02 21:13\n",
      "Epoch 473 of 550 took 180.918s\n",
      "  training loss:\t\t0.000224\n",
      "  validation loss:\t\t0.008282\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 474 started on 2016-07-02 21:16\n",
      "Epoch 474 of 550 took 180.862s\n",
      "  training loss:\t\t0.000156\n",
      "  validation loss:\t\t0.007705\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 475 started on 2016-07-02 21:19\n",
      "Epoch 475 of 550 took 180.869s\n",
      "  training loss:\t\t0.000223\n",
      "  validation loss:\t\t0.007778\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 476 started on 2016-07-02 21:22\n",
      "Epoch 476 of 550 took 180.905s\n",
      "  training loss:\t\t0.000279\n",
      "  validation loss:\t\t0.008417\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 477 started on 2016-07-02 21:25\n",
      "Epoch 477 of 550 took 180.874s\n",
      "  training loss:\t\t0.000188\n",
      "  validation loss:\t\t0.008475\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 478 started on 2016-07-02 21:28\n",
      "Epoch 478 of 550 took 180.911s\n",
      "  training loss:\t\t0.000229\n",
      "  validation loss:\t\t0.009246\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 479 started on 2016-07-02 21:31\n",
      "Epoch 479 of 550 took 180.894s\n",
      "  training loss:\t\t0.000125\n",
      "  validation loss:\t\t0.009113\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 480 started on 2016-07-02 21:34\n",
      "Epoch 480 of 550 took 180.875s\n",
      "  training loss:\t\t0.000096\n",
      "  validation loss:\t\t0.008515\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 481 started on 2016-07-02 21:37\n",
      "Epoch 481 of 550 took 180.909s\n",
      "  training loss:\t\t0.000138\n",
      "  validation loss:\t\t0.007359\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 482 started on 2016-07-02 21:40\n",
      "Epoch 482 of 550 took 180.913s\n",
      "  training loss:\t\t0.000184\n",
      "  validation loss:\t\t0.006916\n",
      "  validation accuracy:\t\t99.89 %\n",
      "Epoch 483 started on 2016-07-02 21:43\n",
      "Epoch 483 of 550 took 180.922s\n",
      "  training loss:\t\t0.000131\n",
      "  validation loss:\t\t0.008498\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 484 started on 2016-07-02 21:46\n",
      "Epoch 484 of 550 took 180.927s\n",
      "  training loss:\t\t0.000143\n",
      "  validation loss:\t\t0.012623\n",
      "  validation accuracy:\t\t99.82 %\n",
      "Epoch 485 started on 2016-07-02 21:49\n",
      "Epoch 485 of 550 took 180.922s\n",
      "  training loss:\t\t0.000100\n",
      "  validation loss:\t\t0.008938\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 486 started on 2016-07-02 21:52\n",
      "Epoch 486 of 550 took 180.915s\n",
      "  training loss:\t\t0.000090\n",
      "  validation loss:\t\t0.008283\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 487 started on 2016-07-02 21:55\n",
      "Epoch 487 of 550 took 180.919s\n",
      "  training loss:\t\t0.000120\n",
      "  validation loss:\t\t0.009204\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 488 started on 2016-07-02 21:58\n",
      "Epoch 488 of 550 took 180.903s\n",
      "  training loss:\t\t0.000180\n",
      "  validation loss:\t\t0.009709\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 489 started on 2016-07-02 22:01\n",
      "Epoch 489 of 550 took 180.903s\n",
      "  training loss:\t\t0.000199\n",
      "  validation loss:\t\t0.010076\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 490 started on 2016-07-02 22:04\n",
      "Epoch 490 of 550 took 180.899s\n",
      "  training loss:\t\t0.000173\n",
      "  validation loss:\t\t0.008923\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 491 started on 2016-07-02 22:07\n",
      "Epoch 491 of 550 took 180.905s\n",
      "  training loss:\t\t0.000099\n",
      "  validation loss:\t\t0.009537\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 492 started on 2016-07-02 22:10\n",
      "Epoch 492 of 550 took 180.903s\n",
      "  training loss:\t\t0.000139\n",
      "  validation loss:\t\t0.009976\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 493 started on 2016-07-02 22:13\n",
      "Epoch 493 of 550 took 180.889s\n",
      "  training loss:\t\t0.000145\n",
      "  validation loss:\t\t0.008417\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 494 started on 2016-07-02 22:16\n",
      "Epoch 494 of 550 took 180.906s\n",
      "  training loss:\t\t0.000126\n",
      "  validation loss:\t\t0.009107\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 495 started on 2016-07-02 22:19\n",
      "Epoch 495 of 550 took 180.897s\n",
      "  training loss:\t\t0.000149\n",
      "  validation loss:\t\t0.006824\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 496 started on 2016-07-02 22:22\n",
      "Epoch 496 of 550 took 180.868s\n",
      "  training loss:\t\t0.000120\n",
      "  validation loss:\t\t0.009540\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 497 started on 2016-07-02 22:25\n",
      "Epoch 497 of 550 took 180.874s\n",
      "  training loss:\t\t0.000135\n",
      "  validation loss:\t\t0.010581\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 498 started on 2016-07-02 22:28\n",
      "Epoch 498 of 550 took 180.868s\n",
      "  training loss:\t\t0.000092\n",
      "  validation loss:\t\t0.009769\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 499 started on 2016-07-02 22:31\n",
      "Epoch 499 of 550 took 180.894s\n",
      "  training loss:\t\t0.000153\n",
      "  validation loss:\t\t0.009480\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 500 started on 2016-07-02 22:34\n",
      "Epoch 500 of 550 took 180.891s\n",
      "  training loss:\t\t0.000155\n",
      "  validation loss:\t\t0.008661\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 501 started on 2016-07-02 22:37\n",
      "Epoch 501 of 550 took 180.896s\n",
      "  training loss:\t\t0.000215\n",
      "  validation loss:\t\t0.008955\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 502 started on 2016-07-02 22:40\n",
      "Epoch 502 of 550 took 180.892s\n",
      "  training loss:\t\t0.000212\n",
      "  validation loss:\t\t0.009387\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 503 started on 2016-07-02 22:43\n",
      "Epoch 503 of 550 took 180.870s\n",
      "  training loss:\t\t0.000329\n",
      "  validation loss:\t\t0.009825\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 504 started on 2016-07-02 22:46\n",
      "Epoch 504 of 550 took 180.874s\n",
      "  training loss:\t\t0.000262\n",
      "  validation loss:\t\t0.009266\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 505 started on 2016-07-02 22:49\n",
      "Epoch 505 of 550 took 180.908s\n",
      "  training loss:\t\t0.000094\n",
      "  validation loss:\t\t0.010881\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 506 started on 2016-07-02 22:52\n",
      "Epoch 506 of 550 took 180.856s\n",
      "  training loss:\t\t0.000190\n",
      "  validation loss:\t\t0.009822\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 507 started on 2016-07-02 22:55\n",
      "Epoch 507 of 550 took 180.874s\n",
      "  training loss:\t\t0.000157\n",
      "  validation loss:\t\t0.008668\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 508 started on 2016-07-02 22:58\n",
      "Epoch 508 of 550 took 180.880s\n",
      "  training loss:\t\t0.000154\n",
      "  validation loss:\t\t0.010465\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 509 started on 2016-07-02 23:01\n",
      "Epoch 509 of 550 took 180.881s\n",
      "  training loss:\t\t0.000223\n",
      "  validation loss:\t\t0.009582\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 510 started on 2016-07-02 23:04\n",
      "Epoch 510 of 550 took 180.860s\n",
      "  training loss:\t\t0.000155\n",
      "  validation loss:\t\t0.009165\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 511 started on 2016-07-02 23:07\n",
      "Epoch 511 of 550 took 180.836s\n",
      "  training loss:\t\t0.000236\n",
      "  validation loss:\t\t0.009734\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 512 started on 2016-07-02 23:10\n",
      "Epoch 512 of 550 took 180.853s\n",
      "  training loss:\t\t0.000177\n",
      "  validation loss:\t\t0.007832\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 513 started on 2016-07-02 23:13\n",
      "Epoch 513 of 550 took 180.861s\n",
      "  training loss:\t\t0.000257\n",
      "  validation loss:\t\t0.010137\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 514 started on 2016-07-02 23:16\n",
      "Epoch 514 of 550 took 180.911s\n",
      "  training loss:\t\t0.000284\n",
      "  validation loss:\t\t0.010754\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 515 started on 2016-07-02 23:19\n",
      "Epoch 515 of 550 took 180.905s\n",
      "  training loss:\t\t0.000199\n",
      "  validation loss:\t\t0.008142\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 516 started on 2016-07-02 23:22\n",
      "Epoch 516 of 550 took 180.881s\n",
      "  training loss:\t\t0.000109\n",
      "  validation loss:\t\t0.009434\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 517 started on 2016-07-02 23:25\n",
      "Epoch 517 of 550 took 180.897s\n",
      "  training loss:\t\t0.000309\n",
      "  validation loss:\t\t0.010256\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 518 started on 2016-07-02 23:28\n",
      "Epoch 518 of 550 took 180.881s\n",
      "  training loss:\t\t0.000266\n",
      "  validation loss:\t\t0.009260\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 519 started on 2016-07-02 23:31\n",
      "Epoch 519 of 550 took 180.858s\n",
      "  training loss:\t\t0.000236\n",
      "  validation loss:\t\t0.008864\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 520 started on 2016-07-02 23:34\n",
      "Epoch 520 of 550 took 180.915s\n",
      "  training loss:\t\t0.000241\n",
      "  validation loss:\t\t0.010112\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 521 started on 2016-07-02 23:37\n",
      "Epoch 521 of 550 took 180.876s\n",
      "  training loss:\t\t0.000148\n",
      "  validation loss:\t\t0.008659\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 522 started on 2016-07-02 23:40\n",
      "Epoch 522 of 550 took 180.910s\n",
      "  training loss:\t\t0.000219\n",
      "  validation loss:\t\t0.009380\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 523 started on 2016-07-02 23:43\n",
      "Epoch 523 of 550 took 180.884s\n",
      "  training loss:\t\t0.000094\n",
      "  validation loss:\t\t0.007607\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 524 started on 2016-07-02 23:46\n",
      "Epoch 524 of 550 took 180.902s\n",
      "  training loss:\t\t0.000162\n",
      "  validation loss:\t\t0.008807\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 525 started on 2016-07-02 23:49\n",
      "Epoch 525 of 550 took 180.910s\n",
      "  training loss:\t\t0.000187\n",
      "  validation loss:\t\t0.009751\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 526 started on 2016-07-02 23:52\n",
      "Epoch 526 of 550 took 180.887s\n",
      "  training loss:\t\t0.000128\n",
      "  validation loss:\t\t0.012081\n",
      "  validation accuracy:\t\t99.83 %\n",
      "Epoch 527 started on 2016-07-02 23:56\n",
      "Epoch 527 of 550 took 180.900s\n",
      "  training loss:\t\t0.000242\n",
      "  validation loss:\t\t0.008074\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 528 started on 2016-07-02 23:59\n",
      "Epoch 528 of 550 took 180.898s\n",
      "  training loss:\t\t0.000193\n",
      "  validation loss:\t\t0.009210\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 529 started on 2016-07-03 00:02\n",
      "Epoch 529 of 550 took 180.911s\n",
      "  training loss:\t\t0.000206\n",
      "  validation loss:\t\t0.007833\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 530 started on 2016-07-03 00:05\n",
      "Epoch 530 of 550 took 180.886s\n",
      "  training loss:\t\t0.000177\n",
      "  validation loss:\t\t0.009733\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 531 started on 2016-07-03 00:08\n",
      "Epoch 531 of 550 took 180.903s\n",
      "  training loss:\t\t0.000177\n",
      "  validation loss:\t\t0.007908\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 532 started on 2016-07-03 00:11\n",
      "Epoch 532 of 550 took 180.886s\n",
      "  training loss:\t\t0.000113\n",
      "  validation loss:\t\t0.008154\n",
      "  validation accuracy:\t\t99.88 %\n",
      "Epoch 533 started on 2016-07-03 00:14\n",
      "Epoch 533 of 550 took 180.901s\n",
      "  training loss:\t\t0.000166\n",
      "  validation loss:\t\t0.011981\n",
      "  validation accuracy:\t\t99.84 %\n",
      "Epoch 534 started on 2016-07-03 00:17\n",
      "Epoch 534 of 550 took 180.883s\n",
      "  training loss:\t\t0.000125\n",
      "  validation loss:\t\t0.010331\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 535 started on 2016-07-03 00:20\n",
      "Epoch 535 of 550 took 180.860s\n",
      "  training loss:\t\t0.000217\n",
      "  validation loss:\t\t0.010314\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 536 started on 2016-07-03 00:23\n",
      "Epoch 536 of 550 took 180.872s\n",
      "  training loss:\t\t0.000126\n",
      "  validation loss:\t\t0.009467\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 537 started on 2016-07-03 00:26\n",
      "Epoch 537 of 550 took 180.854s\n",
      "  training loss:\t\t0.000106\n",
      "  validation loss:\t\t0.010219\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 538 started on 2016-07-03 00:29\n",
      "Epoch 538 of 550 took 180.886s\n",
      "  training loss:\t\t0.000244\n",
      "  validation loss:\t\t0.009661\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 539 started on 2016-07-03 00:32\n",
      "Epoch 539 of 550 took 180.894s\n",
      "  training loss:\t\t0.000124\n",
      "  validation loss:\t\t0.008684\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 540 started on 2016-07-03 00:35\n",
      "Epoch 540 of 550 took 180.858s\n",
      "  training loss:\t\t0.000193\n",
      "  validation loss:\t\t0.009007\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 541 started on 2016-07-03 00:38\n",
      "Epoch 541 of 550 took 180.892s\n",
      "  training loss:\t\t0.000136\n",
      "  validation loss:\t\t0.009143\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 542 started on 2016-07-03 00:41\n",
      "Epoch 542 of 550 took 180.864s\n",
      "  training loss:\t\t0.000167\n",
      "  validation loss:\t\t0.010417\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 543 started on 2016-07-03 00:44\n",
      "Epoch 543 of 550 took 180.866s\n",
      "  training loss:\t\t0.000108\n",
      "  validation loss:\t\t0.009981\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 544 started on 2016-07-03 00:47\n",
      "Epoch 544 of 550 took 180.852s\n",
      "  training loss:\t\t0.000095\n",
      "  validation loss:\t\t0.008376\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 545 started on 2016-07-03 00:50\n",
      "Epoch 545 of 550 took 180.825s\n",
      "  training loss:\t\t0.000117\n",
      "  validation loss:\t\t0.009474\n",
      "  validation accuracy:\t\t99.85 %\n",
      "Epoch 546 started on 2016-07-03 00:53\n",
      "Epoch 546 of 550 took 180.859s\n",
      "  training loss:\t\t0.000153\n",
      "  validation loss:\t\t0.008743\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 547 started on 2016-07-03 00:56\n",
      "Epoch 547 of 550 took 180.870s\n",
      "  training loss:\t\t0.000102\n",
      "  validation loss:\t\t0.009943\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 548 started on 2016-07-03 00:59\n",
      "Epoch 548 of 550 took 180.896s\n",
      "  training loss:\t\t0.000145\n",
      "  validation loss:\t\t0.009994\n",
      "  validation accuracy:\t\t99.86 %\n",
      "Epoch 549 started on 2016-07-03 01:02\n",
      "Epoch 549 of 550 took 180.898s\n",
      "  training loss:\t\t0.000147\n",
      "  validation loss:\t\t0.007917\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Epoch 550 started on 2016-07-03 01:05\n",
      "Epoch 550 of 550 took 180.864s\n",
      "  training loss:\t\t0.000119\n",
      "  validation loss:\t\t0.008523\n",
      "  validation accuracy:\t\t99.87 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.011549\n",
      "  test accuracy:\t\t99.88 %\n"
     ]
    }
   ],
   "source": [
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var) # multiclass_hinge_loss\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                    dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(\"Epoch %d started on %s\" % (epoch + 1, now.strftime(\"%Y-%m-%d %H:%M\")))\n",
    "    \n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, batchsize, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batchsize, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "\n",
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, batchsize, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE NETWORK\n",
    "np.savez('../model_needle_july3.npz', *lasagne.layers.get_all_param_values(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwith np.load('../model_needle_july1.npz') as f:\\n    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\\nlasagne.layers.set_all_param_values(network, param_values)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD NETWORK\n",
    "\"\"\"\n",
    "with np.load('../model_needle_july1.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values(network, param_values)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "predict_fn = theano.function([input_var], T.argmax(test_prediction, axis=1))\n",
    "predict_confidence = theano.function([input_var], test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ind = 17\n",
    "a = X_test[ind,:,:,:].reshape((1,3*((2*half_patch_size)+1),(2*half_patch_size)+1,(2*half_patch_size)+1))\n",
    "predict_label_patch = predict_fn(a)[0]\n",
    "\n",
    "print(predict_label_patch, y_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9508889ed0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f950cc5bbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(a[0,5,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 175, 160)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_pat_sitk = sitk.ReadImage('LabelMaps/64/case.nrrd')\n",
    "test_pat = sitk.GetArrayFromImage(sitk.ReadImage('../LabelMaps/64/case.nrrd')).astype(np.float32)\n",
    "test_pat = test_pat[140:,15:180,80:230]\n",
    "test_pat = pad_volume(test_pat, half_patch_size=half_patch_size)\n",
    "\n",
    "pat_sitk = sitk.GetImageFromArray(test_pat.astype(np.float32))\n",
    "sitk.WriteImage(pat_sitk, '../test_pat.nrrd')\n",
    "\n",
    "final_label = np.zeros_like(test_pat)\n",
    "test_pat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "z_size, x_size, y_size = test_pat.shape\n",
    "\n",
    "for z in xrange(half_patch_size, z_size-half_patch_size):\n",
    "    print(z)\n",
    "    for x in xrange(half_patch_size, x_size-half_patch_size):\n",
    "        for y in xrange(half_patch_size, y_size-half_patch_size):\n",
    "            patient_patch_img = test_pat[z-half_patch_size:z+half_patch_size+1,x-half_patch_size:x+half_patch_size+1,y-half_patch_size:y+half_patch_size+1]\n",
    "            patient_patch = patchimg2differentview(patient_patch_img).reshape((1,3*((2*half_patch_size)+1),(2*half_patch_size)+1,(2*half_patch_size)+1)).astype(np.float32)\n",
    "            patient_patch -= m\n",
    "            patient_patch /= s\n",
    "            predicted_label = int(predict_fn(patient_patch)[0])\n",
    "            \n",
    "            final_label[z,x,y] = predicted_label\n",
    "\n",
    "final_label_sitk = sitk.GetImageFromArray(final_label)\n",
    "sitk.WriteImage(final_label_sitk, '../test_label.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
