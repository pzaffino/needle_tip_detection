{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5004)\n",
      "/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import lasagne\n",
    "from copy import deepcopy\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import random\n",
    "from skimage import exposure\n",
    "from skimage.morphology import binary_closing\n",
    "\n",
    "import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_patches(mri, label, half_patch_size=5, negative_subsample_ratio=200):\n",
    "    \n",
    "    assert mri.shape == label.shape\n",
    "    \n",
    "    z_size, x_size, y_size = mri.shape\n",
    "    positive_patches = []\n",
    "    negative_patches = []\n",
    "    \n",
    "    if np.sum(label) <= 0.5:\n",
    "        return ([], [])\n",
    "\n",
    "    for z in xrange(half_patch_size, z_size-half_patch_size):\n",
    "        if label[z,:,:].sum() > 1000: continue # workaround to remove white slices into the label dataset\n",
    "        for x in xrange(half_patch_size, x_size-half_patch_size):\n",
    "            for y in xrange(half_patch_size, y_size-half_patch_size):\n",
    "                if label[z,x,y] == 1:\n",
    "                    positive_patches.append(mri[z-half_patch_size:z+half_patch_size+1,x-half_patch_size:x+half_patch_size+1,y-half_patch_size:y+half_patch_size+1])\n",
    "                elif label[z,x,y] == 0:\n",
    "                    negative_patches.append(mri[z-half_patch_size:z+half_patch_size+1,x-half_patch_size:x+half_patch_size+1,y-half_patch_size:y+half_patch_size+1])\n",
    "    \n",
    "    random.shuffle(negative_patches)\n",
    "    number_of_negative_cases = int(len(negative_patches) / float(negative_subsample_ratio))\n",
    "    selected_negative_patches = deepcopy(negative_patches[:number_of_negative_cases])\n",
    "    del(negative_patches)\n",
    "    \n",
    "    return (positive_patches, selected_negative_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patchimg2differentview(patch):\n",
    "    \n",
    "    z_size, x_size, y_size = patch.shape\n",
    "    \n",
    "    X = np.zeros((z_size * 3, x_size, y_size), dtype=np.float32)\n",
    "    \n",
    "    counter = 0\n",
    "    for z in xrange(z_size):\n",
    "        X[counter,:,:] = patch[z,:,:]\n",
    "        counter += 1\n",
    "    for x in xrange(x_size):\n",
    "        X[counter,:,:] = patch[:,x,:]\n",
    "        counter += 1\n",
    "    for y in xrange(y_size):\n",
    "        X[counter,:,:] = patch[:,:,y]\n",
    "        counter += 1\n",
    "    \n",
    "    return X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patches2CNNformat(patches, label, half_patch_size=5):\n",
    "    \n",
    "    X = np.zeros((len(patches), (2 * half_patch_size)+1, (half_patch_size*2)+1, (half_patch_size*2)+1), dtype=np.float32)\n",
    "    y = np.zeros((len(patches)), dtype=np.int32) * -1\n",
    "    \n",
    "    for i, patch in enumerate(patches):\n",
    "        #X[i,:,:,:] = patchimg2differentview(patch)\n",
    "        X[i,:,:,:] = patch\n",
    "        y[i] = label\n",
    "    \n",
    "    assert -1 not in y\n",
    "    \n",
    "    return X.astype(np.float32), y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_resized_img(img, data_type = sitk.sitkFloat32):\n",
    "    \n",
    "    size = img.GetSize()\n",
    "    ratio = [1.0/i for i in img.GetSpacing()]\n",
    "    new_size = [int(size[i]/ratio[i]) for i in range(3)]\n",
    "    \n",
    "    rimage = sitk.Image(new_size, data_type)\n",
    "    rimage.SetSpacing((1,1,1))\n",
    "    rimage.SetOrigin(img.GetOrigin())\n",
    "    tx = sitk.Transform()\n",
    "    \n",
    "    interp = sitk.sitkLinear\n",
    "    if data_type == sitk.sitkInt16:\n",
    "        interp = sitk.sitkNearestNeighbor\n",
    "    \n",
    "    new_image = sitk.Resample(img, rimage, tx, interp, data_type)\n",
    "    \n",
    "    return sitk.GetArrayFromImage(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def needles2tips(only_needles, image_array, number_of_slices=3):\n",
    "    needles_masks_array = np.zeros_like(image_array).astype(float)  \n",
    "    for file_item in only_needles:\n",
    "        this_mask = file_item.astype(np.float)\n",
    "        if np.sum(this_mask) < (np.shape(this_mask)[0] * np.shape(this_mask)[1] * np.shape(this_mask)[2]):\n",
    "            this_mask = binary_closing(this_mask,selem=np.ones((3,3,3)))\n",
    "            found=False\n",
    "            row = np.shape(this_mask)[0]-1\n",
    "            while found==False and row > 0: #< np.shape(this_mask)[0]-1 :\n",
    "                #print(row)\n",
    "                this_row = this_mask[row,:,:]\n",
    "                if np.sum(this_row) > 0:\n",
    "                    #print(row)\n",
    "                    found = True\n",
    "                    temp = np.add(needles_masks_array[row:row+1+number_of_slices,:,:],this_mask[row:row+1+number_of_slices,:,:])\n",
    "                    temp[temp!=0] = 1\n",
    "                    needles_masks_array[row:row+1+number_of_slices,:,:] = temp \n",
    "                row -= 1\n",
    "    return needles_masks_array.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def needles2tips_PAOLO(needles, mri, number_of_slices=3):\n",
    "    tips = np.zeros_like(mri).astype(np.int32)\n",
    "    #print(tips.shape)\n",
    "    for needle in needles:\n",
    "        needle = needle.astype(np.int32)\n",
    "        #print(\"MIN %f, MAX %f\" % (needle.min(), needle.max()))\n",
    "        if np.sum(needle) < (np.shape(needle)[0] * np.shape(needle)[1] * np.shape(needle)[2]):\n",
    "            #print(\"Valid needle\")\n",
    "            needle = binary_closing(needle, selem=np.ones((3,3,3)))\n",
    "            needle[needle!=0]=1\n",
    "            #print(\" after closing: MIN %f, MAX %f \" % (needle.min(), needle.max()))\n",
    "            for z in range(np.shape(mri)[0]-1, 0, -1):\n",
    "                if 200 > np.sum(needle[z,:,:]) > 0.5 and z-number_of_slices-1 >= 0:\n",
    "                    #print(\" valid slice %d\" % z)\n",
    "                    tmp = deepcopy(needle)\n",
    "                    tmp[:z-number_of_slices-1,:,:] = 0\n",
    "                    tips[tmp!=0] = 1\n",
    "                    del(tmp)\n",
    "                    break\n",
    "    \n",
    "    tips[tips!=0]=1\n",
    "        \n",
    "    return tips.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_needles(needles, mri):\n",
    "    all_needles = np.zeros_like(mri).astype(np.int32)\n",
    "    \n",
    "    for needle in needles:\n",
    "        needle = needle.astype(np.int32)\n",
    "        needle[needle!=0]=1\n",
    "        \n",
    "        if np.sum(needle) < (needle.shape[0] * needle.shape[1] * needle.shape[2])/3.0:\n",
    "            all_needles[needle!=0] = 1\n",
    "    \n",
    "    all_needles[all_needles!=0]=1\n",
    "        \n",
    "    return all_needles.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad_volume(img, half_patch_size=5):\n",
    "    npad = ((half_patch_size,half_patch_size),(half_patch_size,half_patch_size),(half_patch_size,half_patch_size))\n",
    "    return np.lib.pad(img, npad, \"constant\", constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_for_CNN(general_folder, half_patch_size=5):\n",
    "    folders_cases = os.listdir(general_folder)\n",
    "    \n",
    "    X_pos = np.ones((1, (2 * half_patch_size)+1, (half_patch_size*2)+1, (half_patch_size*2)+1), dtype=np.float32) * -1.0\n",
    "    y_pos = np.ones((1), dtype=np.int32) * -1.0\n",
    "    \n",
    "    X_neg = np.ones((1, (2 * half_patch_size)+1, (half_patch_size*2)+1, (half_patch_size*2)+1), dtype=np.float32) * -1.0\n",
    "    y_neg = np.ones((1), dtype=np.int32) * -1.0\n",
    "    \n",
    "    for folder_case in folders_cases:\n",
    "        print(\"Patient #%s\" % (folder_case))\n",
    "        full_case_path = general_folder + os.sep + folder_case\n",
    "        \n",
    "        volumetric_files = os.listdir(full_case_path)\n",
    "        \n",
    "        assert \"case.nrrd\" in volumetric_files\n",
    "        del(volumetric_files[volumetric_files.index(\"case.nrrd\")])\n",
    "        print(\" %d needles file\" %  (len(volumetric_files)))\n",
    "\n",
    "        \n",
    "        mri_sitk = sitk.ReadImage(full_case_path + os.sep + \"case.nrrd\")\n",
    "        \n",
    "        needles = []\n",
    "        valid_needles = 0\n",
    "        for volumetric_file in volumetric_files:\n",
    "            if volumetric_file == \"labelmap.nrrd\":\n",
    "                pass\n",
    "            label_sitk = sitk.ReadImage(full_case_path + os.sep + volumetric_file)\n",
    "            label = sitk.GetArrayFromImage(label_sitk)\n",
    "            background = int(np.around(np.percentile(label, 75), decimals=0))\n",
    "            #print('Background %d' % background)\n",
    "            filtered_label = np.zeros_like(label, dtype=np.int32)\n",
    "            filtered_label[label!=background] = 1\n",
    "            #print(np.sum(filtered_label))\n",
    "            \n",
    "            #label[label!=0]=1\n",
    "            if np.sum(filtered_label)>0:\n",
    "                needles.append(filtered_label)\n",
    "                valid_needles += 1\n",
    "                \n",
    "        print(\" %d valid needles\" %  (valid_needles))\n",
    "        \n",
    "        tips = merge_needles(needles, sitk.GetArrayFromImage(mri_sitk))\n",
    "        #tips_sitk = sitk.GetImageFromArray(tips)\n",
    "        #tips_sitk.CopyInformation(mri_sitk)\n",
    "        #tips = get_resized_img(tips_sitk, sitk.sitkInt16)\n",
    "        tips = pad_volume(tips, half_patch_size=half_patch_size)\n",
    "        tips[tips!=0]=1\n",
    "        \n",
    "        for z in range(tips.shape[0]):\n",
    "            if np.sum(tips[z,:,:]) > 500:\n",
    "                tips[z,:,:] = np.zeros_like(tips[z,:,:], dtype=np.int32)\n",
    "        \n",
    "        tips[tips!=0]=1\n",
    "        tips = tips.astype(np.int32)\n",
    "        #assert np.sum(tips) > 0.5\n",
    "        \n",
    "        mri = sitk.GetArrayFromImage(mri_sitk).astype(np.float32)\n",
    "        mri = pad_volume(mri, half_patch_size=half_patch_size)\n",
    "        \n",
    "        # DEBUG\n",
    "        #data_tag = str(datetime.datetime.now()).replace(\" \", \"_\")\n",
    "        #mri_sitk_DEBUG = sitk.GetImageFromArray(mri)\n",
    "        #tips_sitk_DEBUG = sitk.GetImageFromArray(tips)\n",
    "        #tips_sitk_DEBUG.CopyInformation(mri_sitk_DEBUG)\n",
    "        #sitk.WriteImage(mri_sitk_DEBUG, \"../DEBUG/mri_%s.nrrd\" % data_tag)\n",
    "        #sitk.WriteImage(tips_sitk_DEBUG, \"../DEBUG/tips_%s.nrrd\" % data_tag)\n",
    "        \n",
    "        positive_patches, negative_patches = extract_patches(mri, tips, half_patch_size=half_patch_size)\n",
    "        if len(positive_patches) > 0:\n",
    "            print(\" %d positive patches and %d negative patches\" % (len(positive_patches), len(negative_patches)))\n",
    "            X_temp_pos, y_temp_pos = patches2CNNformat(positive_patches, 1, half_patch_size=half_patch_size)\n",
    "            X_temp_neg, y_temp_neg = patches2CNNformat(negative_patches, 0, half_patch_size=half_patch_size)\n",
    "            \n",
    "            X_pos = np.concatenate((X_pos, X_temp_pos), axis=0)\n",
    "            y_pos = np.concatenate((y_pos, y_temp_pos), axis=0)\n",
    "            X_neg = np.concatenate((X_neg, X_temp_neg), axis=0)\n",
    "            y_neg = np.concatenate((y_neg, y_temp_neg), axis=0)\n",
    "    \n",
    "    assert -1 in X_pos[0,:,:,:] and y_pos[0] == -1\n",
    "    X_pos = X_pos[1:,:,:,:].astype(np.float32)\n",
    "    y_pos = y_pos[1:].astype(np.int32)\n",
    "    \n",
    "    assert -1 in X_neg[0,:,:,:] and y_neg[0] == -1\n",
    "    X_neg = X_neg[1:,:,:,:].astype(np.float32)\n",
    "    y_neg = y_neg[1:].astype(np.int32)\n",
    "    \n",
    "    return X_pos, y_pos, X_neg, y_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_Xy_posneg(X_pos, y_pos, X_neg, y_neg, test_size1=0.20, test_size2=0.33):\n",
    "    \n",
    "    X_pos_train, X_pos_test, y_pos_train, y_pos_test = sklearn.cross_validation.train_test_split(X_pos, y_pos, test_size=test_size1)\n",
    "    X_pos_test, X_pos_val, y_pos_test, y_pos_val = sklearn.cross_validation.train_test_split(X_pos_test, y_pos_test, test_size=test_size2)\n",
    "\n",
    "    X_neg_train, X_neg_test, y_neg_train, y_neg_test = sklearn.cross_validation.train_test_split(X_neg, y_neg, test_size=test_size1)\n",
    "    X_neg_test, X_neg_val, y_neg_test, y_neg_val = sklearn.cross_validation.train_test_split(X_neg_test, y_neg_test, test_size=test_size2)\n",
    "\n",
    "    X_train = np.concatenate((X_neg_train, X_pos_train), axis=0).astype(np.float32)\n",
    "    y_train = np.concatenate((y_neg_train, y_pos_train), axis=0).astype(np.int32)\n",
    "\n",
    "    X_val = np.concatenate((X_neg_val, X_pos_val), axis=0).astype(np.float32)\n",
    "    y_val = np.concatenate((y_neg_val, y_pos_val), axis=0).astype(np.int32)\n",
    "\n",
    "    X_test = np.concatenate((X_neg_test, X_pos_test), axis=0).astype(np.float32)\n",
    "    y_test = np.concatenate((y_neg_test, y_pos_test), axis=0).astype(np.int32)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half_patch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient #072\n",
      " 21 needles file\n",
      " 21 valid needles\n",
      " 17506 positive patches and 56072 negative patches\n",
      "Patient #008\n",
      " 9 needles file\n",
      " 9 valid needles\n",
      " 3204 positive patches and 15583 negative patches\n",
      "Patient #071\n",
      " 14 needles file\n",
      " 14 valid needles\n",
      " 10650 positive patches and 67221 negative patches\n",
      "Patient #076\n",
      " 13 needles file\n",
      " 12 valid needles\n",
      " 11322 positive patches and 52300 negative patches\n",
      "Patient #022\n",
      " 8 needles file\n",
      " 8 valid needles\n",
      " 7383 positive patches and 58043 negative patches\n",
      "Patient #012\n",
      " 10 needles file\n",
      " 10 valid needles\n",
      " 4112 positive patches and 17779 negative patches\n",
      "Patient #069\n",
      " 36 needles file\n",
      " 36 valid needles\n",
      " 29573 positive patches and 52209 negative patches\n",
      "Patient #056\n",
      " 13 needles file\n",
      " 13 valid needles\n",
      " 7642 positive patches and 61158 negative patches\n",
      "Patient #007\n",
      " 8 needles file\n",
      " 8 valid needles\n",
      " 4952 positive patches and 30695 negative patches\n",
      "Patient #053\n",
      " 9 needles file\n",
      " 9 valid needles\n",
      " 7905 positive patches and 49328 negative patches\n",
      "Patient #041\n",
      " 33 needles file\n",
      " 33 valid needles\n",
      " 28091 positive patches and 52217 negative patches\n",
      "Patient #035\n",
      " 18 needles file\n",
      " 18 valid needles\n",
      " 15728 positive patches and 56081 negative patches\n",
      "Patient #026\n",
      " 15 needles file\n",
      " 15 valid needles\n",
      " 13879 positive patches and 67205 negative patches\n",
      "Patient #048\n",
      " 20 needles file\n",
      " 20 valid needles\n",
      " 17741 positive patches and 67186 negative patches\n",
      "Patient #039\n",
      " 16 needles file\n",
      " 16 valid needles\n",
      " 10864 positive patches and 44698 negative patches\n",
      "Patient #024\n",
      " 8 needles file\n",
      " 8 valid needles\n",
      " 3477 positive patches and 15582 negative patches\n",
      "Patient #025\n",
      " 10 needles file\n",
      " 10 valid needles\n",
      " 5222 positive patches and 44726 negative patches\n",
      "Patient #033\n",
      " 6 needles file\n",
      " 6 valid needles\n",
      " 4448 positive patches and 56137 negative patches\n",
      "Patient #027\n",
      " 6 needles file\n",
      " 6 valid needles\n",
      " 1171 positive patches and 21594 negative patches\n",
      "Patient #021\n",
      " 7 needles file\n",
      " 7 valid needles\n",
      " 1527 positive patches and 15392 negative patches\n",
      "Patient #064\n",
      " 20 needles file\n",
      " 20 valid needles\n",
      " 18387 positive patches and 56068 negative patches\n",
      "Patient #059\n",
      " 36 needles file\n",
      " 34 valid needles\n",
      " 32898 positive patches and 67110 negative patches\n",
      "Patient #063\n",
      " 27 needles file\n",
      " 27 valid needles\n",
      " 24301 positive patches and 67153 negative patches\n",
      "Patient #060\n",
      " 12 needles file\n",
      " 11 valid needles\n",
      " 7601 positive patches and 44714 negative patches\n",
      "Patient #070\n",
      " 16 needles file\n",
      " 16 valid needles\n",
      " 11873 positive patches and 67215 negative patches\n",
      "Patient #034\n",
      " 8 needles file\n",
      " 8 valid needles\n",
      " 3712 positive patches and 20679 negative patches\n",
      "Patient #074\n",
      " 17 needles file\n",
      " 15 valid needles\n",
      " 11551 positive patches and 59612 negative patches\n",
      "Patient #029\n",
      " 9 needles file\n",
      " 9 valid needles\n",
      " 3960 positive patches and 49348 negative patches\n",
      "Patient #031\n",
      " 17 needles file\n",
      " 16 valid needles\n",
      " 15801 positive patches and 74508 negative patches\n",
      "Patient #044\n",
      " 15 needles file\n",
      " 15 valid needles\n",
      " 10493 positive patches and 49315 negative patches\n",
      "Patient #014\n",
      " 9 needles file\n",
      " 9 valid needles\n",
      " 2107 positive patches and 20687 negative patches\n",
      "Patient #023\n",
      " 15 needles file\n",
      " 15 valid needles\n",
      " 7913 positive patches and 47960 negative patches\n",
      "Patient #075\n",
      " 8 needles file\n",
      " 8 valid needles\n",
      " 5760 positive patches and 52328 negative patches\n",
      "Patient #077\n",
      " 8 needles file\n",
      " 8 valid needles\n",
      " 3898 positive patches and 48535 negative patches\n",
      "Patient #037\n",
      " 7 needles file\n",
      " 7 valid needles\n",
      " 4127 positive patches and 44731 negative patches\n",
      "Patient #030\n",
      " 16 needles file\n",
      " 16 valid needles\n",
      " 7878 positive patches and 52318 negative patches\n",
      "Patient #040\n",
      " 15 needles file\n",
      " 15 valid needles\n",
      " 9122 positive patches and 45651 negative patches\n",
      "Patient #042\n",
      " 19 needles file\n",
      " 19 valid needles\n",
      " 7309 positive patches and 26305 negative patches\n",
      "Patient #058\n",
      " 12 needles file\n",
      " 12 valid needles\n",
      " 5440 positive patches and 55840 negative patches\n",
      "Patient #038\n",
      " 10 needles file\n",
      " 10 valid needles\n",
      " 7820 positive patches and 65087 negative patches\n",
      "Patient #050\n",
      " 21 needles file\n",
      " 21 valid needles\n",
      " 17851 positive patches and 52268 negative patches\n",
      "Patient #045\n",
      " 18 needles file\n",
      " 18 valid needles\n",
      " 8964 positive patches and 52312 negative patches\n",
      "Patient #016\n",
      " 16 needles file\n",
      " 16 valid needles\n",
      " 3866 positive patches and 26323 negative patches\n",
      "Patient #049\n",
      " 10 needles file\n",
      " 10 valid needles\n",
      " 8957 positive patches and 59625 negative patches\n"
     ]
    }
   ],
   "source": [
    "X_pos, y_pos, X_neg, y_neg = data_for_CNN(\"../LabelMaps\", half_patch_size=half_patch_size)\n",
    "#saved_data = np.load('../patches_jun27_halfpatchsize5odd.npz')\n",
    "#X, y = saved_data['arr_0'], saved_data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.savez('../patches_jul1_halfpatchsize5odd.npz', X_pos, y_pos, X_neg, y_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-72420694c08c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_pos' is not defined"
     ]
    }
   ],
   "source": [
    "X_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = join_Xy_posneg(X_pos, y_pos, X_neg, y_neg, test_size1=0.20, test_size2=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, s = X_train.mean(), X_train.std()\n",
    "\n",
    "X_train -= m\n",
    "X_train /= s\n",
    "\n",
    "X_val -= m\n",
    "X_val /= s\n",
    "\n",
    "X_test -= m\n",
    "X_test /= s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('meanandstd_jan10.npz', m=m, s=s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2043906, 11, 11, 11), (342354, 11, 11, 11), (168624, 11, 11, 11))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=True):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(single_entry_shape, input_var=None):\n",
    "    \n",
    "    network = lasagne.layers.InputLayer(shape=(None, single_entry_shape[0], single_entry_shape[1], \n",
    "                                               single_entry_shape[2]),\n",
    "                                        input_var=input_var)\n",
    "    \n",
    "    network = lasagne.layers.batch_norm(lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=480, filter_size=(3, 3),  #120\n",
    "            nonlinearity=lasagne.nonlinearities.leaky_rectify,\n",
    "            W=lasagne.init.HeNormal()))\n",
    "    #network = lasagne.layers.MaxPool2DLayer(network, pool_size=(2, 2))\n",
    "    \n",
    "    network = lasagne.layers.batch_norm(lasagne.layers.Conv2DLayer(\n",
    "            network, num_filters=240, filter_size=(2, 2), #120\n",
    "            nonlinearity=lasagne.nonlinearities.leaky_rectify))\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "           lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=120, #120*2*2\n",
    "           nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "           lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=60,\n",
    "           nonlinearity=lasagne.nonlinearities.leaky_rectify)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(\n",
    "            lasagne.layers.dropout(network, p=.5),\n",
    "            num_units=2,\n",
    "            nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batchsize = 128\n",
    "single_entry_shape = X_train.shape[1:]\n",
    "\n",
    "# Prepare Theano variables for inputs and targets\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "network = build_cnn(single_entry_shape, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1 started on 2017-01-10 22:51\n",
      "Epoch 1 of 100 took 591.950s\n",
      "  training loss:\t\t0.109968\n",
      "  validation loss:\t\t0.060122\n",
      "  validation accuracy:\t\t97.91 %\n",
      "Epoch 2 started on 2017-01-10 23:01\n",
      "Epoch 2 of 100 took 591.309s\n",
      "  training loss:\t\t0.068601\n",
      "  validation loss:\t\t0.050052\n",
      "  validation accuracy:\t\t98.23 %\n",
      "Epoch 3 started on 2017-01-10 23:11\n",
      "Epoch 3 of 100 took 591.422s\n",
      "  training loss:\t\t0.057193\n",
      "  validation loss:\t\t0.047465\n",
      "  validation accuracy:\t\t98.39 %\n",
      "Epoch 4 started on 2017-01-10 23:21\n",
      "Epoch 4 of 100 took 591.380s\n",
      "  training loss:\t\t0.051307\n",
      "  validation loss:\t\t0.035734\n",
      "  validation accuracy:\t\t98.81 %\n",
      "Epoch 5 started on 2017-01-10 23:31\n",
      "Epoch 5 of 100 took 591.414s\n",
      "  training loss:\t\t0.047360\n",
      "  validation loss:\t\t0.033911\n",
      "  validation accuracy:\t\t98.84 %\n",
      "Epoch 6 started on 2017-01-10 23:40\n",
      "Epoch 6 of 100 took 591.391s\n",
      "  training loss:\t\t0.044675\n",
      "  validation loss:\t\t0.032945\n",
      "  validation accuracy:\t\t98.92 %\n",
      "Epoch 7 started on 2017-01-10 23:50\n",
      "Epoch 7 of 100 took 591.366s\n",
      "  training loss:\t\t0.042511\n",
      "  validation loss:\t\t0.030198\n",
      "  validation accuracy:\t\t98.98 %\n",
      "Epoch 8 started on 2017-01-11 00:00\n",
      "Epoch 8 of 100 took 591.510s\n",
      "  training loss:\t\t0.040787\n",
      "  validation loss:\t\t0.031029\n",
      "  validation accuracy:\t\t98.99 %\n",
      "Epoch 9 started on 2017-01-11 00:10\n",
      "Epoch 9 of 100 took 591.608s\n",
      "  training loss:\t\t0.039191\n",
      "  validation loss:\t\t0.028776\n",
      "  validation accuracy:\t\t99.04 %\n",
      "Epoch 10 started on 2017-01-11 00:20\n",
      "Epoch 10 of 100 took 591.490s\n",
      "  training loss:\t\t0.037974\n",
      "  validation loss:\t\t0.027047\n",
      "  validation accuracy:\t\t99.09 %\n",
      "Epoch 11 started on 2017-01-11 00:30\n",
      "Epoch 11 of 100 took 591.473s\n",
      "  training loss:\t\t0.036765\n",
      "  validation loss:\t\t0.027583\n",
      "  validation accuracy:\t\t99.07 %\n",
      "Epoch 12 started on 2017-01-11 00:40\n",
      "Epoch 12 of 100 took 591.584s\n",
      "  training loss:\t\t0.035617\n",
      "  validation loss:\t\t0.027201\n",
      "  validation accuracy:\t\t99.10 %\n",
      "Epoch 13 started on 2017-01-11 00:49\n",
      "Epoch 13 of 100 took 591.567s\n",
      "  training loss:\t\t0.034960\n",
      "  validation loss:\t\t0.025741\n",
      "  validation accuracy:\t\t99.12 %\n",
      "Epoch 14 started on 2017-01-11 00:59\n",
      "Epoch 14 of 100 took 591.615s\n",
      "  training loss:\t\t0.033835\n",
      "  validation loss:\t\t0.024889\n",
      "  validation accuracy:\t\t99.15 %\n",
      "Epoch 15 started on 2017-01-11 01:09\n",
      "Epoch 15 of 100 took 591.424s\n",
      "  training loss:\t\t0.032796\n",
      "  validation loss:\t\t0.023899\n",
      "  validation accuracy:\t\t99.21 %\n",
      "Epoch 16 started on 2017-01-11 01:19\n",
      "Epoch 16 of 100 took 591.461s\n",
      "  training loss:\t\t0.032187\n",
      "  validation loss:\t\t0.024988\n",
      "  validation accuracy:\t\t99.16 %\n",
      "Epoch 17 started on 2017-01-11 01:29\n",
      "Epoch 17 of 100 took 591.533s\n",
      "  training loss:\t\t0.031656\n",
      "  validation loss:\t\t0.024000\n",
      "  validation accuracy:\t\t99.23 %\n",
      "Epoch 18 started on 2017-01-11 01:39\n",
      "Epoch 18 of 100 took 591.460s\n",
      "  training loss:\t\t0.030960\n",
      "  validation loss:\t\t0.023814\n",
      "  validation accuracy:\t\t99.22 %\n",
      "Epoch 19 started on 2017-01-11 01:49\n",
      "Epoch 19 of 100 took 591.486s\n",
      "  training loss:\t\t0.030384\n",
      "  validation loss:\t\t0.022449\n",
      "  validation accuracy:\t\t99.25 %\n",
      "Epoch 20 started on 2017-01-11 01:58\n",
      "Epoch 20 of 100 took 591.557s\n",
      "  training loss:\t\t0.029992\n",
      "  validation loss:\t\t0.022636\n",
      "  validation accuracy:\t\t99.23 %\n",
      "Epoch 21 started on 2017-01-11 02:08\n",
      "Epoch 21 of 100 took 591.623s\n",
      "  training loss:\t\t0.029162\n",
      "  validation loss:\t\t0.021814\n",
      "  validation accuracy:\t\t99.29 %\n",
      "Epoch 22 started on 2017-01-11 02:18\n",
      "Epoch 22 of 100 took 591.480s\n",
      "  training loss:\t\t0.028619\n",
      "  validation loss:\t\t0.021327\n",
      "  validation accuracy:\t\t99.30 %\n",
      "Epoch 23 started on 2017-01-11 02:28\n",
      "Epoch 23 of 100 took 591.549s\n",
      "  training loss:\t\t0.028195\n",
      "  validation loss:\t\t0.021412\n",
      "  validation accuracy:\t\t99.29 %\n",
      "Epoch 24 started on 2017-01-11 02:38\n",
      "Epoch 24 of 100 took 591.584s\n",
      "  training loss:\t\t0.027770\n",
      "  validation loss:\t\t0.020959\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 25 started on 2017-01-11 02:48\n",
      "Epoch 25 of 100 took 591.358s\n",
      "  training loss:\t\t0.027402\n",
      "  validation loss:\t\t0.020307\n",
      "  validation accuracy:\t\t99.34 %\n",
      "Epoch 26 started on 2017-01-11 02:58\n",
      "Epoch 26 of 100 took 591.438s\n",
      "  training loss:\t\t0.026984\n",
      "  validation loss:\t\t0.020349\n",
      "  validation accuracy:\t\t99.35 %\n",
      "Epoch 27 started on 2017-01-11 03:07\n",
      "Epoch 27 of 100 took 591.417s\n",
      "  training loss:\t\t0.026473\n",
      "  validation loss:\t\t0.020846\n",
      "  validation accuracy:\t\t99.33 %\n",
      "Epoch 28 started on 2017-01-11 03:17\n",
      "Epoch 28 of 100 took 591.482s\n",
      "  training loss:\t\t0.026184\n",
      "  validation loss:\t\t0.020272\n",
      "  validation accuracy:\t\t99.34 %\n",
      "Epoch 29 started on 2017-01-11 03:27\n",
      "Epoch 29 of 100 took 591.426s\n",
      "  training loss:\t\t0.025770\n",
      "  validation loss:\t\t0.019862\n",
      "  validation accuracy:\t\t99.36 %\n",
      "Epoch 30 started on 2017-01-11 03:37\n",
      "Epoch 30 of 100 took 592.583s\n",
      "  training loss:\t\t0.025304\n",
      "  validation loss:\t\t0.018778\n",
      "  validation accuracy:\t\t99.41 %\n",
      "Epoch 31 started on 2017-01-11 03:47\n",
      "Epoch 31 of 100 took 591.545s\n",
      "  training loss:\t\t0.025095\n",
      "  validation loss:\t\t0.018236\n",
      "  validation accuracy:\t\t99.43 %\n",
      "Epoch 32 started on 2017-01-11 03:57\n",
      "Epoch 32 of 100 took 591.533s\n",
      "  training loss:\t\t0.024852\n",
      "  validation loss:\t\t0.019444\n",
      "  validation accuracy:\t\t99.39 %\n",
      "Epoch 33 started on 2017-01-11 04:07\n",
      "Epoch 33 of 100 took 591.534s\n",
      "  training loss:\t\t0.024380\n",
      "  validation loss:\t\t0.017993\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 34 started on 2017-01-11 04:17\n",
      "Epoch 34 of 100 took 591.574s\n",
      "  training loss:\t\t0.024052\n",
      "  validation loss:\t\t0.017694\n",
      "  validation accuracy:\t\t99.47 %\n",
      "Epoch 35 started on 2017-01-11 04:26\n",
      "Epoch 35 of 100 took 591.504s\n",
      "  training loss:\t\t0.023634\n",
      "  validation loss:\t\t0.018547\n",
      "  validation accuracy:\t\t99.42 %\n",
      "Epoch 36 started on 2017-01-11 04:36\n",
      "Epoch 36 of 100 took 591.436s\n",
      "  training loss:\t\t0.023675\n",
      "  validation loss:\t\t0.017580\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 37 started on 2017-01-11 04:46\n",
      "Epoch 37 of 100 took 591.530s\n",
      "  training loss:\t\t0.023124\n",
      "  validation loss:\t\t0.017803\n",
      "  validation accuracy:\t\t99.45 %\n",
      "Epoch 38 started on 2017-01-11 04:56\n",
      "Epoch 38 of 100 took 591.522s\n",
      "  training loss:\t\t0.022935\n",
      "  validation loss:\t\t0.017233\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 39 started on 2017-01-11 05:06\n",
      "Epoch 39 of 100 took 591.396s\n",
      "  training loss:\t\t0.022714\n",
      "  validation loss:\t\t0.017062\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 40 started on 2017-01-11 05:16\n",
      "Epoch 40 of 100 took 591.536s\n",
      "  training loss:\t\t0.022458\n",
      "  validation loss:\t\t0.016526\n",
      "  validation accuracy:\t\t99.50 %\n",
      "Epoch 41 started on 2017-01-11 05:26\n",
      "Epoch 41 of 100 took 591.581s\n",
      "  training loss:\t\t0.022134\n",
      "  validation loss:\t\t0.015742\n",
      "  validation accuracy:\t\t99.54 %\n",
      "Epoch 42 started on 2017-01-11 05:35\n",
      "Epoch 42 of 100 took 591.594s\n",
      "  training loss:\t\t0.022040\n",
      "  validation loss:\t\t0.016242\n",
      "  validation accuracy:\t\t99.52 %\n",
      "Epoch 43 started on 2017-01-11 05:45\n",
      "Epoch 43 of 100 took 591.511s\n",
      "  training loss:\t\t0.021732\n",
      "  validation loss:\t\t0.017005\n",
      "  validation accuracy:\t\t99.48 %\n",
      "Epoch 44 started on 2017-01-11 05:55\n",
      "Epoch 44 of 100 took 591.510s\n",
      "  training loss:\t\t0.021530\n",
      "  validation loss:\t\t0.015918\n",
      "  validation accuracy:\t\t99.52 %\n",
      "Epoch 45 started on 2017-01-11 06:05\n",
      "Epoch 45 of 100 took 591.588s\n",
      "  training loss:\t\t0.021524\n",
      "  validation loss:\t\t0.015959\n",
      "  validation accuracy:\t\t99.52 %\n",
      "Epoch 46 started on 2017-01-11 06:15\n",
      "Epoch 46 of 100 took 591.607s\n",
      "  training loss:\t\t0.020964\n",
      "  validation loss:\t\t0.016767\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 47 started on 2017-01-11 06:25\n",
      "Epoch 47 of 100 took 591.647s\n",
      "  training loss:\t\t0.020875\n",
      "  validation loss:\t\t0.016096\n",
      "  validation accuracy:\t\t99.52 %\n",
      "Epoch 48 started on 2017-01-11 06:35\n",
      "Epoch 48 of 100 took 591.597s\n",
      "  training loss:\t\t0.020692\n",
      "  validation loss:\t\t0.016271\n",
      "  validation accuracy:\t\t99.50 %\n",
      "Epoch 49 started on 2017-01-11 06:44\n",
      "Epoch 49 of 100 took 591.703s\n",
      "  training loss:\t\t0.020499\n",
      "  validation loss:\t\t0.016225\n",
      "  validation accuracy:\t\t99.51 %\n",
      "Epoch 50 started on 2017-01-11 06:54\n",
      "Epoch 50 of 100 took 591.597s\n",
      "  training loss:\t\t0.020188\n",
      "  validation loss:\t\t0.016718\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 51 started on 2017-01-11 07:04\n",
      "Epoch 51 of 100 took 591.506s\n",
      "  training loss:\t\t0.020091\n",
      "  validation loss:\t\t0.017423\n",
      "  validation accuracy:\t\t99.46 %\n",
      "Epoch 52 started on 2017-01-11 07:14\n",
      "Epoch 52 of 100 took 591.493s\n",
      "  training loss:\t\t0.019786\n",
      "  validation loss:\t\t0.015614\n",
      "  validation accuracy:\t\t99.52 %\n",
      "Epoch 53 started on 2017-01-11 07:24\n",
      "Epoch 53 of 100 took 591.390s\n",
      "  training loss:\t\t0.019542\n",
      "  validation loss:\t\t0.016547\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 54 started on 2017-01-11 07:34\n",
      "Epoch 54 of 100 took 591.440s\n",
      "  training loss:\t\t0.019473\n",
      "  validation loss:\t\t0.015408\n",
      "  validation accuracy:\t\t99.54 %\n",
      "Epoch 55 started on 2017-01-11 07:44\n",
      "Epoch 55 of 100 took 591.537s\n",
      "  training loss:\t\t0.019244\n",
      "  validation loss:\t\t0.016851\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 56 started on 2017-01-11 07:53\n",
      "Epoch 56 of 100 took 591.542s\n",
      "  training loss:\t\t0.019112\n",
      "  validation loss:\t\t0.015115\n",
      "  validation accuracy:\t\t99.55 %\n",
      "Epoch 57 started on 2017-01-11 08:03\n",
      "Epoch 57 of 100 took 591.536s\n",
      "  training loss:\t\t0.018916\n",
      "  validation loss:\t\t0.015060\n",
      "  validation accuracy:\t\t99.56 %\n",
      "Epoch 58 started on 2017-01-11 08:13\n",
      "Epoch 58 of 100 took 591.530s\n",
      "  training loss:\t\t0.019018\n",
      "  validation loss:\t\t0.015728\n",
      "  validation accuracy:\t\t99.52 %\n",
      "Epoch 59 started on 2017-01-11 08:23\n",
      "Epoch 59 of 100 took 591.528s\n",
      "  training loss:\t\t0.018602\n",
      "  validation loss:\t\t0.016129\n",
      "  validation accuracy:\t\t99.49 %\n",
      "Epoch 60 started on 2017-01-11 08:33\n",
      "Epoch 60 of 100 took 591.535s\n",
      "  training loss:\t\t0.018655\n",
      "  validation loss:\t\t0.014280\n",
      "  validation accuracy:\t\t99.58 %\n",
      "Epoch 61 started on 2017-01-11 08:43\n",
      "Epoch 61 of 100 took 591.501s\n",
      "  training loss:\t\t0.018078\n",
      "  validation loss:\t\t0.014425\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 62 started on 2017-01-11 08:53\n",
      "Epoch 62 of 100 took 591.475s\n",
      "  training loss:\t\t0.018023\n",
      "  validation loss:\t\t0.014990\n",
      "  validation accuracy:\t\t99.54 %\n",
      "Epoch 63 started on 2017-01-11 09:02\n",
      "Epoch 63 of 100 took 591.527s\n",
      "  training loss:\t\t0.017999\n",
      "  validation loss:\t\t0.014707\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 64 started on 2017-01-11 09:12\n",
      "Epoch 64 of 100 took 591.469s\n",
      "  training loss:\t\t0.017891\n",
      "  validation loss:\t\t0.014631\n",
      "  validation accuracy:\t\t99.56 %\n",
      "Epoch 65 started on 2017-01-11 09:22\n",
      "Epoch 65 of 100 took 591.495s\n",
      "  training loss:\t\t0.017662\n",
      "  validation loss:\t\t0.015264\n",
      "  validation accuracy:\t\t99.53 %\n",
      "Epoch 66 started on 2017-01-11 09:32\n",
      "Epoch 66 of 100 took 591.370s\n",
      "  training loss:\t\t0.017607\n",
      "  validation loss:\t\t0.014459\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 67 started on 2017-01-11 09:42\n",
      "Epoch 67 of 100 took 591.273s\n",
      "  training loss:\t\t0.017261\n",
      "  validation loss:\t\t0.014550\n",
      "  validation accuracy:\t\t99.58 %\n",
      "Epoch 68 started on 2017-01-11 09:52\n",
      "Epoch 68 of 100 took 591.400s\n",
      "  training loss:\t\t0.017379\n",
      "  validation loss:\t\t0.014120\n",
      "  validation accuracy:\t\t99.59 %\n",
      "Epoch 69 started on 2017-01-11 10:02\n",
      "Epoch 69 of 100 took 591.547s\n",
      "  training loss:\t\t0.017002\n",
      "  validation loss:\t\t0.015508\n",
      "  validation accuracy:\t\t99.54 %\n",
      "Epoch 70 started on 2017-01-11 10:11\n",
      "Epoch 70 of 100 took 591.500s\n",
      "  training loss:\t\t0.016912\n",
      "  validation loss:\t\t0.014292\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 71 started on 2017-01-11 10:21\n",
      "Epoch 71 of 100 took 591.452s\n",
      "  training loss:\t\t0.016862\n",
      "  validation loss:\t\t0.013261\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 72 started on 2017-01-11 10:31\n",
      "Epoch 72 of 100 took 591.507s\n",
      "  training loss:\t\t0.016768\n",
      "  validation loss:\t\t0.014392\n",
      "  validation accuracy:\t\t99.59 %\n",
      "Epoch 73 started on 2017-01-11 10:41\n",
      "Epoch 73 of 100 took 591.418s\n",
      "  training loss:\t\t0.016664\n",
      "  validation loss:\t\t0.013021\n",
      "  validation accuracy:\t\t99.63 %\n",
      "Epoch 74 started on 2017-01-11 10:51\n",
      "Epoch 74 of 100 took 591.459s\n",
      "  training loss:\t\t0.016480\n",
      "  validation loss:\t\t0.013889\n",
      "  validation accuracy:\t\t99.58 %\n",
      "Epoch 75 started on 2017-01-11 11:01\n",
      "Epoch 75 of 100 took 591.523s\n",
      "  training loss:\t\t0.016443\n",
      "  validation loss:\t\t0.012575\n",
      "  validation accuracy:\t\t99.65 %\n",
      "Epoch 76 started on 2017-01-11 11:11\n",
      "Epoch 76 of 100 took 591.528s\n",
      "  training loss:\t\t0.016344\n",
      "  validation loss:\t\t0.013932\n",
      "  validation accuracy:\t\t99.59 %\n",
      "Epoch 77 started on 2017-01-11 11:20\n",
      "Epoch 77 of 100 took 591.525s\n",
      "  training loss:\t\t0.016062\n",
      "  validation loss:\t\t0.014107\n",
      "  validation accuracy:\t\t99.57 %\n",
      "Epoch 78 started on 2017-01-11 11:30\n",
      "Epoch 78 of 100 took 591.409s\n",
      "  training loss:\t\t0.016039\n",
      "  validation loss:\t\t0.013679\n",
      "  validation accuracy:\t\t99.60 %\n",
      "Epoch 79 started on 2017-01-11 11:40\n",
      "Epoch 79 of 100 took 591.559s\n",
      "  training loss:\t\t0.016058\n",
      "  validation loss:\t\t0.013465\n",
      "  validation accuracy:\t\t99.61 %\n",
      "Epoch 80 started on 2017-01-11 11:50\n",
      "Epoch 80 of 100 took 591.450s\n",
      "  training loss:\t\t0.015838\n",
      "  validation loss:\t\t0.013254\n",
      "  validation accuracy:\t\t99.61 %\n",
      "Epoch 81 started on 2017-01-11 12:00\n",
      "Epoch 81 of 100 took 591.320s\n",
      "  training loss:\t\t0.015565\n",
      "  validation loss:\t\t0.014009\n",
      "  validation accuracy:\t\t99.59 %\n",
      "Epoch 82 started on 2017-01-11 12:10\n",
      "Epoch 82 of 100 took 591.484s\n",
      "  training loss:\t\t0.015556\n",
      "  validation loss:\t\t0.012689\n",
      "  validation accuracy:\t\t99.64 %\n",
      "Epoch 83 started on 2017-01-11 12:20\n",
      "Epoch 83 of 100 took 591.486s\n",
      "  training loss:\t\t0.015338\n",
      "  validation loss:\t\t0.012627\n",
      "  validation accuracy:\t\t99.64 %\n",
      "Epoch 84 started on 2017-01-11 12:29\n",
      "Epoch 84 of 100 took 591.580s\n",
      "  training loss:\t\t0.015285\n",
      "  validation loss:\t\t0.012898\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 85 started on 2017-01-11 12:39\n",
      "Epoch 85 of 100 took 591.446s\n",
      "  training loss:\t\t0.015254\n",
      "  validation loss:\t\t0.014378\n",
      "  validation accuracy:\t\t99.58 %\n",
      "Epoch 86 started on 2017-01-11 12:49\n",
      "Epoch 86 of 100 took 591.537s\n",
      "  training loss:\t\t0.015171\n",
      "  validation loss:\t\t0.012928\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 87 started on 2017-01-11 12:59\n",
      "Epoch 87 of 100 took 591.433s\n",
      "  training loss:\t\t0.015118\n",
      "  validation loss:\t\t0.012931\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 88 started on 2017-01-11 13:09\n",
      "Epoch 88 of 100 took 591.559s\n",
      "  training loss:\t\t0.014780\n",
      "  validation loss:\t\t0.012965\n",
      "  validation accuracy:\t\t99.63 %\n",
      "Epoch 89 started on 2017-01-11 13:19\n",
      "Epoch 89 of 100 took 591.407s\n",
      "  training loss:\t\t0.014674\n",
      "  validation loss:\t\t0.013157\n",
      "  validation accuracy:\t\t99.61 %\n",
      "Epoch 90 started on 2017-01-11 13:29\n",
      "Epoch 90 of 100 took 591.513s\n",
      "  training loss:\t\t0.014794\n",
      "  validation loss:\t\t0.013481\n",
      "  validation accuracy:\t\t99.60 %\n",
      "Epoch 91 started on 2017-01-11 13:38\n",
      "Epoch 91 of 100 took 591.518s\n",
      "  training loss:\t\t0.014687\n",
      "  validation loss:\t\t0.013030\n",
      "  validation accuracy:\t\t99.63 %\n",
      "Epoch 92 started on 2017-01-11 13:48\n",
      "Epoch 92 of 100 took 591.459s\n",
      "  training loss:\t\t0.014611\n",
      "  validation loss:\t\t0.013138\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 93 started on 2017-01-11 13:58\n",
      "Epoch 93 of 100 took 591.500s\n",
      "  training loss:\t\t0.014438\n",
      "  validation loss:\t\t0.013110\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 94 started on 2017-01-11 14:08\n",
      "Epoch 94 of 100 took 591.502s\n",
      "  training loss:\t\t0.014474\n",
      "  validation loss:\t\t0.013149\n",
      "  validation accuracy:\t\t99.64 %\n",
      "Epoch 95 started on 2017-01-11 14:18\n",
      "Epoch 95 of 100 took 591.480s\n",
      "  training loss:\t\t0.014312\n",
      "  validation loss:\t\t0.012982\n",
      "  validation accuracy:\t\t99.62 %\n",
      "Epoch 96 started on 2017-01-11 14:28\n",
      "Epoch 96 of 100 took 591.492s\n",
      "  training loss:\t\t0.014160\n",
      "  validation loss:\t\t0.012337\n",
      "  validation accuracy:\t\t99.64 %\n",
      "Epoch 97 started on 2017-01-11 14:38\n",
      "Epoch 97 of 100 took 591.442s\n",
      "  training loss:\t\t0.013979\n",
      "  validation loss:\t\t0.011986\n",
      "  validation accuracy:\t\t99.67 %\n",
      "Epoch 98 started on 2017-01-11 14:47\n",
      "Epoch 98 of 100 took 591.513s\n",
      "  training loss:\t\t0.013942\n",
      "  validation loss:\t\t0.012507\n",
      "  validation accuracy:\t\t99.65 %\n",
      "Epoch 99 started on 2017-01-11 14:57\n",
      "Epoch 99 of 100 took 591.522s\n",
      "  training loss:\t\t0.014119\n",
      "  validation loss:\t\t0.012512\n",
      "  validation accuracy:\t\t99.65 %\n",
      "Epoch 100 started on 2017-01-11 15:07\n",
      "Epoch 100 of 100 took 591.457s\n",
      "  training loss:\t\t0.013832\n",
      "  validation loss:\t\t0.013056\n",
      "  validation accuracy:\t\t99.63 %\n",
      "Final results:\n",
      "  test loss:\t\t\t0.014170\n",
      "  test accuracy:\t\t99.61 %\n"
     ]
    }
   ],
   "source": [
    "# Create a loss expression for training, i.e., a scalar objective we want\n",
    "# to minimize (for our multi-class problem, it is the cross-entropy loss):\n",
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var) # multiclass_hinge_loss\n",
    "loss = loss.mean()\n",
    "# We could add some weight decay as well here, see lasagne.regularization.\n",
    "\n",
    "# Create update expressions for training, i.e., how to modify the\n",
    "# parameters at each training step. Here, we'll use Stochastic Gradient\n",
    "# Descent (SGD) with Nesterov momentum, but Lasagne offers plenty more.\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(\n",
    "        loss, params, learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "# Create a loss expression for validation/testing. The crucial difference\n",
    "# here is that we do a deterministic forward pass through the network,\n",
    "# disabling dropout layers.\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                    dtype=theano.config.floatX)\n",
    "\n",
    "# Compile a function performing a training step on a mini-batch (by giving\n",
    "# the updates dictionary) and returning the corresponding training loss:\n",
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "\n",
    "# Compile a second function computing the validation loss and accuracy:\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "\n",
    "# Finally, launch the training loop.\n",
    "print(\"Starting training...\")\n",
    "# We iterate over epochs:\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    print(\"Epoch %d started on %s\" % (epoch + 1, now.strftime(\"%Y-%m-%d %H:%M\")))\n",
    "    \n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, batchsize, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batchsize, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))\n",
    "\n",
    "# After training, we compute and print the test error:\n",
    "test_err = 0\n",
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, batchsize, shuffle=False):\n",
    "    inputs, targets = batch\n",
    "    err, acc = val_fn(inputs, targets)\n",
    "    test_err += err\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test loss:\\t\\t\\t{:.6f}\".format(test_err / test_batches))\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SAVE NETWORK\n",
    "np.savez('model_needle_jan10.npz', *lasagne.layers.get_all_param_values(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD NETWORK\n",
    "\"\"\"\n",
    "with np.load('../model_needle_july1.npz') as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "lasagne.layers.set_all_param_values(network, param_values)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "predict_fn = theano.function([input_var], T.argmax(test_prediction, axis=1))\n",
    "predict_confidence = theano.function([input_var], test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "ind = 17\n",
    "a = X_test[ind,:,:,:].reshape((1,(2*half_patch_size)+1,(2*half_patch_size)+1,(2*half_patch_size)+1))\n",
    "predict_label_patch = predict_fn(a)[0]\n",
    "\n",
    "print(predict_label_patch, y_test[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4fb4dcd050>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFdCAYAAADSR9wBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4faa807890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(a[0,5,:,:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 175, 160)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_pat_sitk = sitk.ReadImage('LabelMaps/64/case.nrrd')\n",
    "test_pat = sitk.GetArrayFromImage(sitk.ReadImage('../testing_pat/002/case.nrrd')).astype(np.float32)\n",
    "test_pat = test_pat[140:,15:180,80:230]\n",
    "test_pat = pad_volume(test_pat, half_patch_size=half_patch_size)\n",
    "\n",
    "pat_sitk = sitk.GetImageFromArray(test_pat.astype(np.float32))\n",
    "sitk.WriteImage(pat_sitk, '../test_pat.nrrd')\n",
    "\n",
    "final_label = np.zeros_like(test_pat)\n",
    "test_pat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "z_size, x_size, y_size = test_pat.shape\n",
    "\n",
    "for z in xrange(half_patch_size, z_size-half_patch_size):\n",
    "    print(z)\n",
    "    for x in xrange(half_patch_size, x_size-half_patch_size):\n",
    "        for y in xrange(half_patch_size, y_size-half_patch_size):\n",
    "            patient_patch_img = test_pat[z-half_patch_size:z+half_patch_size+1,x-half_patch_size:x+half_patch_size+1,y-half_patch_size:y+half_patch_size+1]\n",
    "            #patient_patch = patchimg2differentview(patient_patch_img).reshape((1,3*((2*half_patch_size)+1),(2*half_patch_size)+1,(2*half_patch_size)+1)).astype(np.float32)\n",
    "            patient_patch = patient_patch_img.reshape((1,(2*half_patch_size)+1,(2*half_patch_size)+1,(2*half_patch_size)+1)).astype(np.float32)\n",
    "            patient_patch -= m\n",
    "            patient_patch /= s\n",
    "            predicted_label = int(predict_fn(patient_patch)[0])\n",
    "            \n",
    "            final_label[z,x,y] = predicted_label\n",
    "\n",
    "final_label_sitk = sitk.GetImageFromArray(final_label)\n",
    "sitk.WriteImage(final_label_sitk, '../test_label.nrrd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
